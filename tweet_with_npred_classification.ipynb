{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltvCyedxVFBJ",
        "outputId": "8f60e877-9fde-4d26-c759-354053fa2c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry-IcrbdVRpN",
        "outputId": "5d99b998-010d-4f21-947d-1f72ff949e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: conllu in /usr/local/lib/python3.10/dist-packages (4.5.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install conllu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP3unaiSh35n"
      },
      "source": [
        "# Classifying Tweets from the Financial Market Domain with Predicate Names\n",
        "\n",
        "Our goal is, given a tweet in portuguese from the financial market domain, to classify whether or not this tweet contains a predicate name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7syl1_HNiSFe"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtpA5bAYhzRO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import conllu as c\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw95Kc15ibNu"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzEJNCgdiXXE"
      },
      "outputs": [],
      "source": [
        "npreds = pd.read_csv('npreds_emot.csv')\n",
        "corpus_sem_preds = pd.read_csv('dante_nonpreds.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI844RFLlohr",
        "outputId": "2202af38-ecec-423c-9cee-17aad1583e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1401 entries, 0 to 1400\n",
            "Data columns (total 17 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Unnamed: 0    1401 non-null   int64  \n",
            " 1   tweet_ids     1401 non-null   object \n",
            " 2   text_x        1401 non-null   object \n",
            " 3   TRU           1401 non-null   int64  \n",
            " 4   DIS           1401 non-null   int64  \n",
            " 5   JOY           1401 non-null   int64  \n",
            " 6   SAD           1401 non-null   int64  \n",
            " 7   ANT           1401 non-null   int64  \n",
            " 8   SUR           1401 non-null   int64  \n",
            " 9   ANG           1401 non-null   int64  \n",
            " 10  FEA           1401 non-null   int64  \n",
            " 11  NEUTRAL       1401 non-null   int64  \n",
            " 12  conf_tru_dis  1401 non-null   float64\n",
            " 13  conf_joy_sad  1401 non-null   float64\n",
            " 14  conf_ant_sur  1401 non-null   float64\n",
            " 15  conf_ang_fea  1401 non-null   float64\n",
            " 16  num_annot     1401 non-null   int64  \n",
            "dtypes: float64(4), int64(11), object(2)\n",
            "memory usage: 186.2+ KB\n"
          ]
        }
      ],
      "source": [
        "npreds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WMKurA5YYrk"
      },
      "outputs": [],
      "source": [
        "# conjunto de todos os tweets\n",
        "dante_npreds_conllu = open('tweets_npreds.conllu', \"r\", encoding=\"utf-8\")\n",
        "dante_npreds_parsed = dante_npreds_conllu.read()\n",
        "dante_npreds_conllu.close()\n",
        "dante_npreds_parsed = c.parse(dante_npreds_parsed)\n",
        "\n",
        "dante_npreds = {'tweet_ids': [], 'text': []}\n",
        "\n",
        "for i in range(len(dante_npreds_parsed)):\n",
        "  dante_npreds['tweet_ids'].append(dante_npreds_parsed[i].metadata['sent_id'].split('01_')[1])\n",
        "  dante_npreds['text'].append(dante_npreds_parsed[i].metadata['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYekash7YiOY"
      },
      "outputs": [],
      "source": [
        "dante_npreds = pd.DataFrame(dante_npreds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8qWTIFzkGab"
      },
      "outputs": [],
      "source": [
        "# conjunto de todos os tweets para a versao mais atualizada do dante stocks\n",
        "data = open('DANTEStocks (15dez2022).conllu', \"r\", encoding=\"utf-8\")\n",
        "annotations = data.read()\n",
        "data.close()\n",
        "sentences = c.parse(annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDLLyFnxkX2r"
      },
      "outputs": [],
      "source": [
        "dante_stocks = {'tweet_ids':[], 'text':[]}\n",
        "for i in range(len(sentences)):\n",
        "  dante_stocks['tweet_ids'].append(sentences[i].metadata['sent_id'].split('_01_')[1])\n",
        "  dante_stocks['text'].append(sentences[i].metadata['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rLzSSjUlG9S"
      },
      "outputs": [],
      "source": [
        "dante_stocks = pd.DataFrame(dante_stocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9r4vhKyXlMaR",
        "outputId": "26a2d343-8e10-4a44-d641-e6fa909dcd0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_ids                                               text\n",
              "0  441014389496619009l  #VALE5 - Análise #Ichimoku - pregão de sexta-f...\n",
              "1  441020223408578560l  #PETR4 - Análise #Ichimoku - pregão de sexta-f...\n",
              "2  441028254942502912l  as nuvens do ichimoku: PETR4 - pregão de sexta...\n",
              "3  441030534467055617l  Em a #PETR4 fizemos em a sexta passada uma Sub...\n",
              "4  441032165967814656l  @PaiRico @frfontanella @eddu56 @TiagoBDS Acabe..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ea2534b-8373-4f1e-888e-d4e0fa4020e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_ids</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>441014389496619009l</td>\n",
              "      <td>#VALE5 - Análise #Ichimoku - pregão de sexta-f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>441020223408578560l</td>\n",
              "      <td>#PETR4 - Análise #Ichimoku - pregão de sexta-f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>441028254942502912l</td>\n",
              "      <td>as nuvens do ichimoku: PETR4 - pregão de sexta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>441030534467055617l</td>\n",
              "      <td>Em a #PETR4 fizemos em a sexta passada uma Sub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>441032165967814656l</td>\n",
              "      <td>@PaiRico @frfontanella @eddu56 @TiagoBDS Acabe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ea2534b-8373-4f1e-888e-d4e0fa4020e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ea2534b-8373-4f1e-888e-d4e0fa4020e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ea2534b-8373-4f1e-888e-d4e0fa4020e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c76019f6-e046-4658-9056-a8889f092fe6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c76019f6-e046-4658-9056-a8889f092fe6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c76019f6-e046-4658-9056-a8889f092fe6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dante_stocks",
              "summary": "{\n  \"name\": \"dante_stocks\",\n  \"rows\": 4048,\n  \"fields\": [\n    {\n      \"column\": \"tweet_ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4048,\n        \"samples\": [\n          \"446665209240104960l\",\n          \"441593920347463680l\",\n          \"469865109679259649l\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4048,\n        \"samples\": [\n          \"Queda #petr4 n\\u00e3o apenas gente de dentro da #petrobras mas tamb\\u00e9m empres\\u00e1rios aceitaram negociatas. Estes tamb\\u00e9m s\\u00e3o traidores da p\\u00e1tria!\",\n          \"RT @WallFigueiredo: Rastreamento a\\u00e7\\u00f5es-Gr\\u00e1fico di\\u00e1rio-12h. Analise se romper:  ALLL3 7,09 BBDC4 27,58 IFNC 3997,04 LREN3 58,72  PCAR4 98,92\\u2026\",\n          \"INTRADAY PETR4: Suportes 17,16 e 17,40 e resist\\u00eancias 17,83 e 18,02 INTRADAY VALE5: Suportes 26,21 e 26,42 e resist\\u00eancias 26,86 e 27,09\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dante_stocks.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBbK3d3IlUZt"
      },
      "outputs": [],
      "source": [
        "rows_to_drop = [i for i in range(dante_stocks.shape[0]) if dante_stocks.tweet_ids.to_list()[i] not in corpus_sem_preds.tweet_id.to_list()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW6ctzTIl4pP"
      },
      "outputs": [],
      "source": [
        "dante_stocks.drop(rows_to_drop, axis=0, inplace=True)\n",
        "dante_stocks = dante_stocks.text.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQjYRolkXIhw",
        "outputId": "c0aec7e9-0a57-4ed4-b4cd-dafe907980c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2647\n",
            "1401\n",
            "4048\n"
          ]
        }
      ],
      "source": [
        "print(len(dante_stocks))\n",
        "print(len(npreds))\n",
        "print(len(dante_stocks) + len(npreds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL9ETzLpaled"
      },
      "source": [
        "## Creating Dataframes for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6daKoTsZCuA"
      },
      "outputs": [],
      "source": [
        "npreds_with_target = pd.DataFrame({'text':npreds['text_x'],\n",
        "                                   'target':np.ones(npreds.shape[0])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiXd7RY6bBGl"
      },
      "outputs": [],
      "source": [
        "dante_with_target = pd.DataFrame({'text':dante_stocks,\n",
        "                                  'target':np.zeros(len(dante_stocks))})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDQVSJDKbCyK"
      },
      "outputs": [],
      "source": [
        "data = pd.concat((npreds_with_target, dante_with_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1XPMGTlbX2E"
      },
      "outputs": [],
      "source": [
        "data = data.sample(frac=1, random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAHyTQk9bsMf"
      },
      "outputs": [],
      "source": [
        "data.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "LJCsTaqmbw5k",
        "outputId": "fe5dd6b1-47f0-402f-cfed-13c0a80be88a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='target'>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# very unbalanced\n",
        "data.groupby('target').count().plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BNWqyGdUahYJ",
        "outputId": "01d602c6-edf7-413e-d8c7-9f4ad12399aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  target\n",
              "0     #MRFG3 - Análise #Ichimoku - Recomendação de C...     1.0\n",
              "1     RT @RaphaFigueredo: *** SAIU DO FORNO: RUI FAL...     1.0\n",
              "2     @Live_Trade não, ainda tem a #PETR4 ... ,) hehehe     0.0\n",
              "3     $CYRE3 - Cyrela Realt (cyre-nm) - Demonstracoe...     0.0\n",
              "4     @abilio_diniz @paodeacucar  Análise dos fundam...     0.0\n",
              "...                                                 ...     ...\n",
              "4043  ELET3 bateu no objetivo do Anderson agora,quer...     0.0\n",
              "4044  Rastreamento ações-Gráfico diário-11h. Analise...     0.0\n",
              "4045  A última indicação da #JBSS3 resultou em -4.21...     1.0\n",
              "4046  #LLXL3 minha opiniao é que é mto fundo zerando...     1.0\n",
              "4047  LLXL3 muda de nome na Bolsa e vira PRUMO (PRML...     0.0\n",
              "\n",
              "[4048 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a911a0f-bc8e-4174-abcd-698bfb3c1c91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#MRFG3 - Análise #Ichimoku - Recomendação de C...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @RaphaFigueredo: *** SAIU DO FORNO: RUI FAL...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Live_Trade não, ainda tem a #PETR4 ... ,) hehehe</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>$CYRE3 - Cyrela Realt (cyre-nm) - Demonstracoe...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@abilio_diniz @paodeacucar  Análise dos fundam...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4043</th>\n",
              "      <td>ELET3 bateu no objetivo do Anderson agora,quer...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4044</th>\n",
              "      <td>Rastreamento ações-Gráfico diário-11h. Analise...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4045</th>\n",
              "      <td>A última indicação da #JBSS3 resultou em -4.21...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4046</th>\n",
              "      <td>#LLXL3 minha opiniao é que é mto fundo zerando...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4047</th>\n",
              "      <td>LLXL3 muda de nome na Bolsa e vira PRUMO (PRML...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4048 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a911a0f-bc8e-4174-abcd-698bfb3c1c91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a911a0f-bc8e-4174-abcd-698bfb3c1c91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a911a0f-bc8e-4174-abcd-698bfb3c1c91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-169dcc13-a076-4718-ad85-a949950aef0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-169dcc13-a076-4718-ad85-a949950aef0f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-169dcc13-a076-4718-ad85-a949950aef0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4ffa24a7-2260-4bb3-a16b-571ec32e076f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4ffa24a7-2260-4bb3-a16b-571ec32e076f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 4048,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4048,\n        \"samples\": [\n          \"$ELET3 - Eletrobras (elet-n1) - Fato Relevante E Demonstracoes Financeiras De 31/12/2013 http://t.co/e2NiBfz6vY\",\n          \"A \\u00faltima indica\\u00e7\\u00e3o da #BRAP4 resultou em 6.46 %. Confira a nova indica\\u00e7\\u00e3o agora em http://t.co/kgt1YiTbF7\",\n          \"Bradesco PN (BBDC4), Gr\\u00e1fico Di\\u00e1rio. http://t.co/8nh3KR9rVT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47578328899547845,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvxlYmNqdDnc"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIhKBPb-x90d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D-IFDuVAvoK"
      },
      "outputs": [],
      "source": [
        "X = data.text.to_numpy()\n",
        "y = data.target.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDYZExr8yGnW"
      },
      "outputs": [],
      "source": [
        "train_d, test_d, y_train, y_test = train_test_split(X, y,\n",
        "                                                test_size=0.2,\n",
        "                                                shuffle=True,\n",
        "                                                random_state=0, # trocar semente\n",
        "                                                stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqjgQWVI_qAn",
        "outputId": "4d5baf67-5989-49cc-afa7-d2eefd4f8619"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['GGBR4 vender por R$ 17,84 indicado em 03/01/2014 15:26 http://t.co/zJRs3Eeyz9',\n",
              "       'Quebra de sigilo bancário da #PETR4.. E foi aberta a caixa de PANDORA!!',\n",
              "       'A última indicação de a #ITUB4 resultou em 0.84 %. Confira a nova indicação agora em http://t.co/zJRs3Eeyz9',\n",
              "       ...,\n",
              "       'Estatais em alta: Petrobrás ordinárias, +6,82%, Preferenciais, +6,45%, B.do Brasil, +6,96%, Elet3 +8,46% e Eletr 6, +4,78%',\n",
              "       'Rastreamento ações - Gráfico MENSAL - 11h . Analise se romper : ITUB3 31,77 LAME4 16,85 MDIA3 92,20 PTBL3 5,04 PFRM3 21,53 RADL3 19,13 SMTO3 31,18',\n",
              "       '@clubedopairico #PETR4 com muitos processos la fora sobre lavagem de dinheiro...mas pouco divulgado aqui...pq será? rsrs'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "train_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH1lO4dYLNFk"
      },
      "outputs": [],
      "source": [
        "# test_d, val_d, y_test, y_val = train_test_split(test_d, y_test,\n",
        "#                                                 test_size=0.5,\n",
        "#                                                 random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGof67ClSYDs",
        "outputId": "476c1a90-dac6-4ff0-a0f5-8d58835f6565"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1.]), array([2117, 1121]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "np.unique(y_train, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkicei_jRbxH",
        "outputId": "f6f9a280-c1ce-47c3-83de-ea0f6ea06e69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1.]), array([530, 280]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "np.unique(y_test, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3t2FWADLYmX"
      },
      "outputs": [],
      "source": [
        "# np.unique(y_val, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyJnV5bh2wMq"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "In order to tokenize the data so as to create embeddings of the tokens, we must first remove punctuations, special characters and URLs that are prevelant in our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72Ko7gvm6mPc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbpQVlL6d3C9"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    # lower case\n",
        "    text = text.lower()\n",
        "\n",
        "    # removes the type of URL we see in our data\n",
        "    text = re.sub('http://t\\.co/[A-Za-z0-9]+', '', text)\n",
        "\n",
        "    # removes r$\n",
        "    text = re.sub('[rR]\\$', '', text)\n",
        "\n",
        "    # removes any HTML text\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "\n",
        "    # # substitutes decimal numbers to placeholder\n",
        "    text = re.sub(r'\\b\\d+\\.\\d+\\b', ' valordecimal ', text)\n",
        "    text = re.sub(r'\\b\\d+\\,\\d+\\b', ' valordecimal ', text)\n",
        "\n",
        "    # removes punctuation\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "\n",
        "    # removes spaces\n",
        "    text = re.sub('\\n', '', text)\n",
        "\n",
        "    # substitutes tickers to placeholder\n",
        "    # text = re.sub('\\s*(\\$|#)[a-zA-Z]{4}\\d+\\s*', ' stktkr ', text)\n",
        "    # text = re.sub('\\s*[a-zA-Z]{4}\\d+\\s*', ' stktkr ', text)\n",
        "\n",
        "    # substitutes rt for retweet, q for que and c for com\n",
        "    text = re.sub('\\s*(rt)\\s+', ' retweet ', text)\n",
        "    text = re.sub('\\s*(q)\\s+', ' que ', text)\n",
        "    text = re.sub('\\s*(c)\\s+', ' com ', text)\n",
        "\n",
        "    # substitutes multiple spaces to one space\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwus6QNz6PqR"
      },
      "outputs": [],
      "source": [
        "ct_train = [clean_text(t) for t in train_d]\n",
        "ct_test = [clean_text(t) for t in test_d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zqpUiJgFNN0"
      },
      "source": [
        "## Tokenizing and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ6o9EZnDPma"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "73bec8a13ee6454db4cb2fd30f523f5d",
            "3fe00bcb9d0d49db9babc64763e28358",
            "bf9d45ba21c44ef1ba2c43c8164ff757",
            "3b5729845e314eb6844736178f00fe11",
            "519c10b64354467b969de7b49505d9b2",
            "6a568882217e43f59ff2f1121e11acae",
            "269164f83c3240a0b3c8b0bb25400579",
            "4ccd7c071e1145a4802af093be600864",
            "32e4a833a36c4c69aca39ddae935dbfe",
            "2074e8869e9046158c1a886d3ce5ae5d",
            "78d1bc0051104ec5adcde9acf2881b72",
            "4508965c7b734a2e810a7707185bc25c",
            "4dc1cb57bf674eb6a7cb9902f2a6b82a",
            "aeebb7da7bd44f15a91732ccd0131841",
            "dd3ab474a25140e49bbc62de49cf211d",
            "37209e7e66d8444b88497c5f2611185d",
            "7a77f048fbd34f5fb5bd2f71e137fa4c",
            "6f5637d5f3334db3a984a3152e192d62",
            "e5e5c85b139847faaf6811907cee6453",
            "fe698f695cf547a9b853513d3b657b51",
            "230af5c4e7354214a7b7244fccbd27b1",
            "3e1ba2c5797749f6af3ced3dc9828d55",
            "5a0fd43d371c45e28da9483ea0feb2cb",
            "593aace367da45edbaae9122da2cb5e2",
            "6c436a5be82a4c358596b0dbd69b036a",
            "623cd133b2fd436bb7c2717a7800c3bf",
            "7eb0f5daee6c437abdc9440c89e96ee5",
            "b71bf916bf774d5cbdf74f97a3ca98e6",
            "323b6da1680547d89573cbd0487d9677",
            "9a8b390af4f046fb809a04441affeb7c",
            "f3c2701518764e3da59b42490d99a881",
            "7ca81a0d0fdc42c2ad8aa18175d0873a",
            "e1f9a57c62f94b52b94662f4a57567d7",
            "ed5dab8d790f48f1a3823a875d07786c",
            "5d477052323f4c0baa9192670eab2631",
            "a3c07f07f50f415f81ff15d7f441041f",
            "e08fd94f146948fc926ef8b483152a4c",
            "0dbe4912fbee4112b65dce395bf840f0",
            "7587d26fb0334dbbb5037702ed6d76b7",
            "9350727722e3444f9117bd78384636ff",
            "b3d3513aaba64a32b8328f3cc277b6a7",
            "ed03d76d2287451ab2ae8f15f4ba14b1",
            "8c860fee792c4bd5be4ff4df79748358",
            "33967797d6eb4237aeefe0e6bf516ba1",
            "90b34504b85846e993391301b393994d",
            "5664bc5dbc754951b2b4294dc74895b1",
            "e40097ea8db0424f97abe00257b559b3",
            "0c34ce03fe5448148669c3a150e2846e",
            "caf3bf3230874937af99aec95fd5d29e",
            "2b76ec919c384594bf463a08b124ebf7",
            "8f3056d613204616a7fd4dd232669601",
            "33c5d1d816064828a81e5e0db0252746",
            "9e6007714e5342c2b8460ffe2be87ca8",
            "a9bdd6175b9746288a5dac4762ad640b",
            "0c7cc40f395b4f80b6602d2b8f79778d"
          ]
        },
        "id": "cmVbhcX3Fxvl",
        "outputId": "fa2fccfd-1bf7-42ac-c894-aa1a789d1cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73bec8a13ee6454db4cb2fd30f523f5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4508965c7b734a2e810a7707185bc25c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a0fd43d371c45e28da9483ea0feb2cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed5dab8d790f48f1a3823a875d07786c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90b34504b85846e993391301b393994d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5y9w6faFzwu",
        "outputId": "6b95e1f7-6a87-4219-f357-20a428854786"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# checking maximum sentence size\n",
        "max_length=-10\n",
        "for t in train_d:\n",
        "  t_size = len(t.split(' '))\n",
        "  if t_size > max_length:\n",
        "    max_length = t_size\n",
        "\n",
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHzsSaAfHPx7"
      },
      "outputs": [],
      "source": [
        "def tok_func(text):\n",
        "  return tokenizer(text,\n",
        "                   padding='max_length',\n",
        "                   max_length=128,\n",
        "                   return_tensors='pt',\n",
        "                   truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K8-yBc_HhoO"
      },
      "outputs": [],
      "source": [
        "class NpredDataset(Dataset):\n",
        "\n",
        "  def __init__(self, text, labels):\n",
        "\n",
        "    self.text = text\n",
        "    self.labels = labels\n",
        "    #self.tok = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    encoded_text = tok_func(self.text[idx])\n",
        "\n",
        "    item = {'input_ids':encoded_text['input_ids'],\n",
        "            'attention_mask':encoded_text['attention_mask'],\n",
        "            'labels':self.labels[idx]}\n",
        "    return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VqX2OHuTQEn"
      },
      "outputs": [],
      "source": [
        "train_ds = NpredDataset(train_d, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlct6mm_Y8fa"
      },
      "outputs": [],
      "source": [
        "test_ds = NpredDataset(test_d, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPYooIxdLh8n"
      },
      "outputs": [],
      "source": [
        "# val_ds = NpredDataset(val_d, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pst9PwRqJXzS"
      },
      "outputs": [],
      "source": [
        "# train size is prime so we will set a batch size that\n",
        "# will not divide it equally\n",
        "batch_size = 16\n",
        "\n",
        "train_dlr = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "test_dlr = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
        "# val_dlr = DataLoader(val_ds, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD6smqDcGz6k"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrTMWQz9GzGi"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cljd8uqMqL9K"
      },
      "outputs": [],
      "source": [
        "class NpredModel(nn.Module):\n",
        "\n",
        "  def __init__(self, n_labels):\n",
        "    super(NpredModel, self).__init__()\n",
        "\n",
        "    self.n_labels = n_labels\n",
        "\n",
        "    # BERTimbau model\n",
        "    self.bert = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "    # regularization to avoid overfitting\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    # classification layer\n",
        "    self.linear = nn.Linear(self.bert.config.hidden_size, self.n_labels)\n",
        "\n",
        "    # sigmoid activation function\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "\n",
        "    # get encodings\n",
        "    encod = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    pooled_encod = encod.pooler_output\n",
        "\n",
        "    # apply regularization\n",
        "    x = self.dropout(pooled_encod)\n",
        "\n",
        "    # get output\n",
        "    logits = self.linear(x)\n",
        "\n",
        "    logits = self.sigmoid(logits)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6dcff24b2ad44c66996f9340df9544be",
            "c6be6244592844ab916ff816c03c2046",
            "5b10c98b9999495991ad11e67ef8a5ac",
            "5935b5346ba74552aa81f88e0a713fbf",
            "5c9784bb367e4fe48f9e9d272975598d",
            "850b188f9fb648c08b8a690d3a1b7146",
            "331f7b9da90e48e08d38fdfadc098d0b",
            "a8d4a192722e4e9a91c6310e7f2abb51",
            "15cdf1de4ea34da2802b3000ed12663b",
            "8c72a5fce76344789d929e90c9cf0847",
            "8609ac88b7fb40f7b17c0c2257565e40"
          ]
        },
        "id": "01bKSAZV5UkH",
        "outputId": "21c8378a-940d-4a39-f35f-7e127cbf86d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dcff24b2ad44c66996f9340df9544be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5074]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "a = NpredModel(1)\n",
        "a.forward(input_ids=train_ds[0]['input_ids'],\n",
        "          attention_mask=train_ds[0]['attention_mask'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-vi1E-qIYw6"
      },
      "source": [
        "## Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBtbEGbEpWru"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLyom2uArFV7"
      },
      "outputs": [],
      "source": [
        "def evaluate(m, dtlr, loss):\n",
        "\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    m.eval()\n",
        "    val_running_loss = 0\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "\n",
        "    for batch in dtlr:\n",
        "\n",
        "      # get input ids and attention mask\n",
        "      input_ids = torch.squeeze(batch['input_ids']).to(device)\n",
        "      attention_mask = torch.squeeze(batch['attention_mask']).to(device)\n",
        "      label = batch['labels'].reshape(-1, 1)\n",
        "      label = label.type(torch.float32).to(device)\n",
        "\n",
        "      # forward\n",
        "      output = m(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      # get loss\n",
        "      l = loss(output, label)\n",
        "\n",
        "      # update running loss\n",
        "      val_running_loss += l.item()\n",
        "\n",
        "      # update metrics\n",
        "      ypred = torch.round(output)\n",
        "      predictions.extend(ypred.cpu().detach().numpy())\n",
        "      actual_labels.extend(label.cpu().detach().numpy())\n",
        "\n",
        "    acc = accuracy_score(actual_labels, predictions)\n",
        "    class_rep = classification_report(actual_labels, predictions, labels=[0,1], output_dict=True)\n",
        "    valid_loss = val_running_loss / len(dtlr)\n",
        "    print('Validation Loss: ', valid_loss,\n",
        "          'Validation Accuracy Score: ', acc, '\\n',\n",
        "          'Classification Report: ', class_rep)\n",
        "\n",
        "    return valid_loss, class_rep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip-uznv_1u6w"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wZYz6vY0pBF"
      },
      "outputs": [],
      "source": [
        "def train(m, dlrt, lr, loss):\n",
        "\n",
        "  optm = torch.optim.AdamW(m.parameters(), lr=lr)\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "  m.to(device)\n",
        "  predictions = []\n",
        "  actual_labels = []\n",
        "\n",
        "  m.train()\n",
        "  train_running_loss = 0\n",
        "\n",
        "  for i, batch in enumerate(dlrt):\n",
        "\n",
        "    if (i % 10 == 0) or (i == len(dlrt)):\n",
        "      print('Batch: ', i, '/', len(dlrt))\n",
        "\n",
        "    # zero the gradient\n",
        "    optm.zero_grad()\n",
        "\n",
        "    # get input ids and attention mask\n",
        "    input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "    attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "    label = batch['labels'].reshape(-1, 1)\n",
        "    label = label.type(torch.float32).to(device)\n",
        "\n",
        "\n",
        "    # forward\n",
        "    output = m(input_ids, attention_mask)\n",
        "    ypred = torch.round(output)\n",
        "    predictions.extend(ypred.cpu().detach().numpy())\n",
        "    actual_labels.extend(label.cpu().detach().numpy())\n",
        "\n",
        "    # print(output.shape)\n",
        "    # print(label.shape)\n",
        "\n",
        "    # get loss\n",
        "    l = loss(output, label)\n",
        "\n",
        "    # backpropagate\n",
        "    l.backward()\n",
        "\n",
        "    # step\n",
        "    optm.step()\n",
        "\n",
        "    # update running loss\n",
        "    train_running_loss += l.item()\n",
        "\n",
        "  print('Finished Batch: ')\n",
        "\n",
        "  acc = accuracy_score(actual_labels, predictions)\n",
        "  epoch_loss = train_running_loss / len(dlrt)\n",
        "\n",
        "  print('Training Loss: ', epoch_loss,\n",
        "        'Training Accuracy Score: ', acc)\n",
        "\n",
        "  return epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itdWa_v0voQQ"
      },
      "source": [
        "## Running Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENTvd9_iKgiu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heR0O3AxuvNt"
      },
      "outputs": [],
      "source": [
        "loss = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_Q6JgMRvueI"
      },
      "outputs": [],
      "source": [
        "max_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGhTSV4JxQOJ"
      },
      "outputs": [],
      "source": [
        "lr = 2e-7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p7wg8_PBSI3"
      },
      "outputs": [],
      "source": [
        "model = NpredModel(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSdpnU_iVin1"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVwjRvWH84u2"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "val_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnPCkBzUDhbC"
      },
      "outputs": [],
      "source": [
        "# defining early stopping variables\n",
        "patience = 2\n",
        "min_val_loss = np.inf\n",
        "min_delta = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-ZvCcHgvwr7"
      },
      "outputs": [],
      "source": [
        "# print('##############################', '\\n')\n",
        "# print('#            START           #', '\\n')\n",
        "# print('##############################')\n",
        "# for e in range(max_epochs):\n",
        "#   print('Epoch: ', e, '\\n')\n",
        "#   train_loss = train(model, train_dlr, lr, loss)\n",
        "#   train_losses.append(train_loss)\n",
        "#   val_loss, class_rep = evaluate(model, val_dlr, loss)\n",
        "#   val_losses.append(val_loss)\n",
        "\n",
        "#   # early stopping\n",
        "#   if val_loss < min_val_loss:\n",
        "#     min_val_loss = val_loss\n",
        "#     name = 'model_epoch_' + str(e) + '.pt'\n",
        "#     torch.save(model.state_dict(), 'model.pt')\n",
        "#     patience = 2\n",
        "#   elif val_loss > (min_val_loss + min_delta):\n",
        "#     patience -= 1\n",
        "#     if patience == 0:\n",
        "#       break\n",
        "# print('##############################', '\\n')\n",
        "# print('#             END            #', '\\n')\n",
        "# print('##############################')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuBYT1w4KfZM"
      },
      "outputs": [],
      "source": [
        "# plt.plot(train_losses, label='train')\n",
        "# plt.plot(val_losses, label='val')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgH7cWisKb5c"
      },
      "source": [
        "## Training with Stratified KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbPW_Qxj3rRp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Naq1WGObEykD"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKu_lkiM2PCi"
      },
      "outputs": [],
      "source": [
        "def train_and_eval_with_kfold(X, y, loss, me, min_delta, k=10, lr=2e-7, random_state=0, patience=2):\n",
        "\n",
        "  # declaring random seed\n",
        "  torch.manual_seed(random_state)\n",
        "\n",
        "  # declare kfold\n",
        "  skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
        "\n",
        "  # declaring device\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "  train_losses = {}\n",
        "  val_losses = {}\n",
        "  classification_reports = {}\n",
        "  best_model_weights = {}\n",
        "\n",
        "  for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
        "\n",
        "    train_index = train_index.astype(int)\n",
        "    val_index = val_index.astype(int)\n",
        "\n",
        "    print(f'Fold: {i}')\n",
        "\n",
        "    # creating data based on fold\n",
        "    train_d, test_d = X[train_index], X[val_index]\n",
        "    y_train, y_test = y[train_index], y[val_index]\n",
        "\n",
        "    # saving data\n",
        "    name_xtrain = 'xtrain_data_fold_' + str(i) + '_random_state_' + str(random_state) + '.txt'\n",
        "    name_xtest = 'xval_data_fold_' + str(i) + '_random_state_' + str(random_state) + '.txt'\n",
        "    name_ytrain = 'ytrain_data_fold_' + str(i) + '_random_state_' + str(random_state) + '.txt'\n",
        "    name_ytest = 'yval_data_fold_' + str(i) + '_random_state_' + str(random_state) + '.txt'\n",
        "    np.savetxt(\"results/\" + name_xtrain, train_d, fmt='%s')\n",
        "    np.savetxt(\"results/\" + name_xtest, test_d, fmt='%s')\n",
        "    np.savetxt(\"results/\" + name_ytrain, y_train, fmt='%i')\n",
        "    np.savetxt(\"results/\" + name_ytest, y_test, fmt='%i')\n",
        "\n",
        "    # creating dataloader\n",
        "    train_ds = NpredDataset(train_d, y_train)\n",
        "    test_ds = NpredDataset(test_d, y_test)\n",
        "    train_dlr = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "    test_dlr = DataLoader(test_ds, batch_size=16, shuffle=True)\n",
        "\n",
        "    # declaring the model\n",
        "    m = NpredModel(1)\n",
        "    m.to(device)\n",
        "    fold_train_losses = []\n",
        "    fold_val_losses = []\n",
        "    fold_class_rep = []\n",
        "\n",
        "    # declaring important variables\n",
        "    max_epochs = 100\n",
        "    min_val_loss = np.inf\n",
        "    best_model = None\n",
        "    patience = 2\n",
        "\n",
        "\n",
        "    for e in range(max_epochs):\n",
        "      print('Epoch: ', e, '\\n')\n",
        "      train_loss = train(m, train_dlr, lr, loss)\n",
        "      fold_train_losses.append(train_loss)\n",
        "      val_loss, class_rep = evaluate(m, test_dlr, loss)\n",
        "      fold_val_losses.append(val_loss)\n",
        "      fold_class_rep.append(class_rep)\n",
        "\n",
        "      # early stopping\n",
        "      if val_loss < min_val_loss:\n",
        "\n",
        "        # update lowest validation loss\n",
        "        min_val_loss = val_loss\n",
        "\n",
        "        # saving best model parameters\n",
        "        best_model = m.state_dict()\n",
        "\n",
        "        # reestablish patience\n",
        "        patience = patience\n",
        "\n",
        "      elif val_loss > (min_val_loss + min_delta):\n",
        "\n",
        "        patience -= 1\n",
        "\n",
        "        # save best model\n",
        "        if patience == 0:\n",
        "          name = 'results/model_fold_' + str(i) + '_epoch_' + str(e) + '_random_state' + str(random_state) + '.pth'\n",
        "          torch.save(best_model, name)\n",
        "          # files.download(name)\n",
        "          break\n",
        "\n",
        "    train_losses[i] = fold_train_losses\n",
        "    val_losses[i] = fold_val_losses\n",
        "    classification_reports[i] = fold_class_rep\n",
        "    best_model_weights[i] = best_model\n",
        "\n",
        "  return train_losses, val_losses, classification_reports, best_model_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uWYqM5gRwRK"
      },
      "outputs": [],
      "source": [
        "loss = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4tk9cws-Ewh"
      },
      "outputs": [],
      "source": [
        "me = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k862KHqO-IG4"
      },
      "outputs": [],
      "source": [
        "min_delta = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SFo8LiMp-J9L",
        "outputId": "4b0213f6-6ae9-4955-ea23-944894b06fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 0\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5392193554447648 Training Accuracy Score:  0.7220315717227179\n",
            "Validation Loss:  0.39937816595747355 Validation Accuracy Score:  0.8055555555555556 \n",
            " Classification Report:  {'0': {'precision': 0.7854406130268199, 'recall': 0.9669811320754716, 'f1-score': 0.8668076109936576, 'support': 212}, '1': {'precision': 0.8888888888888888, 'recall': 0.5, 'f1-score': 0.64, 'support': 112}, 'accuracy': 0.8055555555555556, 'macro avg': {'precision': 0.8371647509578544, 'recall': 0.7334905660377358, 'f1-score': 0.7534038054968288, 'support': 324}, 'weighted avg': {'precision': 0.8212005108556834, 'recall': 0.8055555555555556, 'f1-score': 0.7884049800328871, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.2856859256986712 Training Accuracy Score:  0.8843514070006864\n",
            "Validation Loss:  0.30387064530735924 Validation Accuracy Score:  0.8641975308641975 \n",
            " Classification Report:  {'0': {'precision': 0.868421052631579, 'recall': 0.9339622641509434, 'f1-score': 0.9, 'support': 212}, '1': {'precision': 0.8541666666666666, 'recall': 0.7321428571428571, 'f1-score': 0.7884615384615384, 'support': 112}, 'accuracy': 0.8641975308641975, 'macro avg': {'precision': 0.8612938596491229, 'recall': 0.8330525606469003, 'f1-score': 0.8442307692307692, 'support': 324}, 'weighted avg': {'precision': 0.863493610569634, 'recall': 0.8641975308641975, 'f1-score': 0.8614434947768281, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.16732908234692337 Training Accuracy Score:  0.9450926561427591\n",
            "Validation Loss:  0.25292739892999333 Validation Accuracy Score:  0.904320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.9022222222222223, 'recall': 0.9575471698113207, 'f1-score': 0.9290617848970252, 'support': 212}, '1': {'precision': 0.9090909090909091, 'recall': 0.8035714285714286, 'f1-score': 0.8530805687203793, 'support': 112}, 'accuracy': 0.904320987654321, 'macro avg': {'precision': 0.9056565656565656, 'recall': 0.8805592991913747, 'f1-score': 0.8910711768087023, 'support': 324}, 'weighted avg': {'precision': 0.9045965831151016, 'recall': 0.904320987654321, 'f1-score': 0.9027966731322585, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.08641148244076577 Training Accuracy Score:  0.9708304735758407\n",
            "Validation Loss:  0.28462503247317816 Validation Accuracy Score:  0.904320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.905829596412556, 'recall': 0.9528301886792453, 'f1-score': 0.9287356321839081, 'support': 212}, '1': {'precision': 0.900990099009901, 'recall': 0.8125, 'f1-score': 0.8544600938967137, 'support': 112}, 'accuracy': 0.904320987654321, 'macro avg': {'precision': 0.9034098477112285, 'recall': 0.8826650943396226, 'f1-score': 0.891597863040311, 'support': 324}, 'weighted avg': {'precision': 0.9041566837301567, 'recall': 0.904320987654321, 'f1-score': 0.903060137467347, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.04244455968187562 Training Accuracy Score:  0.9879890185312286\n",
            "Validation Loss:  0.3228577315208635 Validation Accuracy Score:  0.904320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.8986784140969163, 'recall': 0.9622641509433962, 'f1-score': 0.9293849658314352, 'support': 212}, '1': {'precision': 0.9175257731958762, 'recall': 0.7946428571428571, 'f1-score': 0.8516746411483254, 'support': 112}, 'accuracy': 0.904320987654321, 'macro avg': {'precision': 0.9081020936463963, 'recall': 0.8784535040431267, 'f1-score': 0.8905298034898803, 'support': 324}, 'weighted avg': {'precision': 0.905193550575569, 'recall': 0.904320987654321, 'f1-score': 0.9025221375459157, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_3847a2c1-ef71-4a51-81ff-1025679e4ae1\", \"model_fold_0.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5946708762906289 Training Accuracy Score:  0.6870281400137268\n",
            "Validation Loss:  0.4858483047712417 Validation Accuracy Score:  0.7438271604938271 \n",
            " Classification Report:  {'0': {'precision': 0.7279151943462897, 'recall': 0.9716981132075472, 'f1-score': 0.8323232323232322, 'support': 212}, '1': {'precision': 0.8536585365853658, 'recall': 0.3125, 'f1-score': 0.45751633986928114, 'support': 112}, 'accuracy': 0.7438271604938271, 'macro avg': {'precision': 0.7907868654658278, 'recall': 0.6420990566037736, 'f1-score': 0.6449197860962567, 'support': 324}, 'weighted avg': {'precision': 0.7713820287005382, 'recall': 0.7438271604938271, 'f1-score': 0.7027603559193973, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.38075182399625984 Training Accuracy Score:  0.8345916266300618\n",
            "Validation Loss:  0.363522660164606 Validation Accuracy Score:  0.8364197530864198 \n",
            " Classification Report:  {'0': {'precision': 0.863013698630137, 'recall': 0.8915094339622641, 'f1-score': 0.877030162412993, 'support': 212}, '1': {'precision': 0.780952380952381, 'recall': 0.7321428571428571, 'f1-score': 0.7557603686635944, 'support': 112}, 'accuracy': 0.8364197530864198, 'macro avg': {'precision': 0.821983039791259, 'recall': 0.8118261455525606, 'f1-score': 0.8163952655382938, 'support': 324}, 'weighted avg': {'precision': 0.8346468233835053, 'recall': 0.8364197530864198, 'f1-score': 0.8351097398823367, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.2318844929378215 Training Accuracy Score:  0.9090597117364447\n",
            "Validation Loss:  0.3406291192486173 Validation Accuracy Score:  0.8580246913580247 \n",
            " Classification Report:  {'0': {'precision': 0.8772727272727273, 'recall': 0.910377358490566, 'f1-score': 0.8935185185185185, 'support': 212}, '1': {'precision': 0.8173076923076923, 'recall': 0.7589285714285714, 'f1-score': 0.7870370370370371, 'support': 112}, 'accuracy': 0.8580246913580247, 'macro avg': {'precision': 0.8472902097902097, 'recall': 0.8346529649595686, 'f1-score': 0.8402777777777778, 'support': 324}, 'weighted avg': {'precision': 0.85654407321074, 'recall': 0.8580246913580247, 'f1-score': 0.8567101051668953, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.12453006165702649 Training Accuracy Score:  0.959162663006177\n",
            "Validation Loss:  0.38771871974070865 Validation Accuracy Score:  0.8796296296296297 \n",
            " Classification Report:  {'0': {'precision': 0.8914027149321267, 'recall': 0.9292452830188679, 'f1-score': 0.9099307159353349, 'support': 212}, '1': {'precision': 0.8543689320388349, 'recall': 0.7857142857142857, 'f1-score': 0.8186046511627907, 'support': 112}, 'accuracy': 0.8796296296296297, 'macro avg': {'precision': 0.8728858234854808, 'recall': 0.8574797843665768, 'f1-score': 0.8642676835490628, 'support': 324}, 'weighted avg': {'precision': 0.8786009134381494, 'recall': 0.8796296296296297, 'f1-score': 0.8783612120633444, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.05250626436404151 Training Accuracy Score:  0.9835277968428278\n",
            "Validation Loss:  0.4555352165230683 Validation Accuracy Score:  0.8827160493827161 \n",
            " Classification Report:  {'0': {'precision': 0.8990825688073395, 'recall': 0.9245283018867925, 'f1-score': 0.9116279069767442, 'support': 212}, '1': {'precision': 0.8490566037735849, 'recall': 0.8035714285714286, 'f1-score': 0.8256880733944955, 'support': 112}, 'accuracy': 0.8827160493827161, 'macro avg': {'precision': 0.8740695862904622, 'recall': 0.8640498652291105, 'f1-score': 0.8686579901856198, 'support': 324}, 'weighted avg': {'precision': 0.8817896426228317, 'recall': 0.8827160493827161, 'f1-score': 0.8819203101828804, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_267c5076-47b1-4368-9bd0-0f70962db218\", \"model_fold_1.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 2\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5577658655050673 Training Accuracy Score:  0.7137954701441318\n",
            "Validation Loss:  0.40680493272486185 Validation Accuracy Score:  0.8302469135802469 \n",
            " Classification Report:  {'0': {'precision': 0.8178137651821862, 'recall': 0.9528301886792453, 'f1-score': 0.8801742919389978, 'support': 212}, '1': {'precision': 0.8701298701298701, 'recall': 0.5982142857142857, 'f1-score': 0.708994708994709, 'support': 112}, 'accuracy': 0.8302469135802469, 'macro avg': {'precision': 0.8439718176560281, 'recall': 0.7755222371967655, 'f1-score': 0.7945845004668534, 'support': 324}, 'weighted avg': {'precision': 0.8358983446702744, 'recall': 0.8302469135802469, 'f1-score': 0.8210011027730708, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.32671981740518996 Training Accuracy Score:  0.8565545641729582\n",
            "Validation Loss:  0.29499344314847675 Validation Accuracy Score:  0.9012345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.8947368421052632, 'recall': 0.9622641509433962, 'f1-score': 0.9272727272727272, 'support': 212}, '1': {'precision': 0.9166666666666666, 'recall': 0.7857142857142857, 'f1-score': 0.8461538461538461, 'support': 112}, 'accuracy': 0.9012345679012346, 'macro avg': {'precision': 0.9057017543859649, 'recall': 0.8739892183288409, 'f1-score': 0.8867132867132868, 'support': 324}, 'weighted avg': {'precision': 0.9023175222005632, 'recall': 0.9012345679012346, 'f1-score': 0.8992316325649659, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.19971952202623008 Training Accuracy Score:  0.924159231297186\n",
            "Validation Loss:  0.3245286987650962 Validation Accuracy Score:  0.8796296296296297 \n",
            " Classification Report:  {'0': {'precision': 0.9219512195121952, 'recall': 0.8915094339622641, 'f1-score': 0.9064748201438848, 'support': 212}, '1': {'precision': 0.8067226890756303, 'recall': 0.8571428571428571, 'f1-score': 0.8311688311688311, 'support': 112}, 'accuracy': 0.8796296296296297, 'macro avg': {'precision': 0.8643369542939128, 'recall': 0.8743261455525606, 'f1-score': 0.868821825656358, 'support': 324}, 'weighted avg': {'precision': 0.8821191349168394, 'recall': 0.8796296296296297, 'f1-score': 0.8804431202512736, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.11266117082918928 Training Accuracy Score:  0.9632807137954701\n",
            "Validation Loss:  0.35314855054907857 Validation Accuracy Score:  0.8981481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.8977777777777778, 'recall': 0.9528301886792453, 'f1-score': 0.9244851258581236, 'support': 212}, '1': {'precision': 0.898989898989899, 'recall': 0.7946428571428571, 'f1-score': 0.8436018957345972, 'support': 112}, 'accuracy': 0.8981481481481481, 'macro avg': {'precision': 0.8983838383838384, 'recall': 0.8737365229110512, 'f1-score': 0.8840435107963605, 'support': 324}, 'weighted avg': {'precision': 0.898196782641227, 'recall': 0.8981481481481481, 'f1-score': 0.8965254907536946, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8017b3e2-7bf2-40ff-b59b-8c16c47c8a68\", \"model_fold_2.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 3\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5685686648217707 Training Accuracy Score:  0.7117364447494853\n",
            "Validation Loss:  0.44251256045841036 Validation Accuracy Score:  0.7870370370370371 \n",
            " Classification Report:  {'0': {'precision': 0.8629441624365483, 'recall': 0.8018867924528302, 'f1-score': 0.8312958435207825, 'support': 212}, '1': {'precision': 0.6692913385826772, 'recall': 0.7589285714285714, 'f1-score': 0.7112970711297071, 'support': 112}, 'accuracy': 0.7870370370370371, 'macro avg': {'precision': 0.7661177505096127, 'recall': 0.7804076819407009, 'f1-score': 0.7712964573252448, 'support': 324}, 'weighted avg': {'precision': 0.7960024455487904, 'recall': 0.7870370370370371, 'f1-score': 0.7898147863979416, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.34742698036744946 Training Accuracy Score:  0.8572409059711736\n",
            "Validation Loss:  0.3536177146292868 Validation Accuracy Score:  0.8333333333333334 \n",
            " Classification Report:  {'0': {'precision': 0.9030612244897959, 'recall': 0.8349056603773585, 'f1-score': 0.8676470588235294, 'support': 212}, '1': {'precision': 0.7265625, 'recall': 0.8303571428571429, 'f1-score': 0.7750000000000001, 'support': 112}, 'accuracy': 0.8333333333333334, 'macro avg': {'precision': 0.8148118622448979, 'recall': 0.8326314016172507, 'f1-score': 0.8213235294117648, 'support': 324}, 'weighted avg': {'precision': 0.8420493197278912, 'recall': 0.8333333333333334, 'f1-score': 0.8356209150326798, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.209615854841601 Training Accuracy Score:  0.924159231297186\n",
            "Validation Loss:  0.33001225831962766 Validation Accuracy Score:  0.8611111111111112 \n",
            " Classification Report:  {'0': {'precision': 0.9073170731707317, 'recall': 0.8773584905660378, 'f1-score': 0.8920863309352518, 'support': 212}, '1': {'precision': 0.7815126050420168, 'recall': 0.8303571428571429, 'f1-score': 0.8051948051948052, 'support': 112}, 'accuracy': 0.8611111111111112, 'macro avg': {'precision': 0.8444148391063743, 'recall': 0.8538578167115903, 'f1-score': 0.8486405680650285, 'support': 324}, 'weighted avg': {'precision': 0.8638291088793241, 'recall': 0.8611111111111112, 'f1-score': 0.8620497541360851, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.10807037914853768 Training Accuracy Score:  0.9673987645847633\n",
            "Validation Loss:  0.39928872368875 Validation Accuracy Score:  0.8734567901234568 \n",
            " Classification Report:  {'0': {'precision': 0.934010152284264, 'recall': 0.8679245283018868, 'f1-score': 0.8997555012224939, 'support': 212}, '1': {'precision': 0.7795275590551181, 'recall': 0.8839285714285714, 'f1-score': 0.8284518828451883, 'support': 112}, 'accuracy': 0.8734567901234568, 'macro avg': {'precision': 0.8567688556696911, 'recall': 0.8759265498652291, 'f1-score': 0.8641036920338412, 'support': 324}, 'weighted avg': {'precision': 0.8806087620322134, 'recall': 0.8734567901234568, 'f1-score': 0.8751073368451536, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.06397313165320644 Training Accuracy Score:  0.9776938915579959\n",
            "Validation Loss:  0.39620955820594517 Validation Accuracy Score:  0.8703703703703703 \n",
            " Classification Report:  {'0': {'precision': 0.9166666666666666, 'recall': 0.8820754716981132, 'f1-score': 0.8990384615384615, 'support': 212}, '1': {'precision': 0.7916666666666666, 'recall': 0.8482142857142857, 'f1-score': 0.8189655172413793, 'support': 112}, 'accuracy': 0.8703703703703703, 'macro avg': {'precision': 0.8541666666666666, 'recall': 0.8651448787061995, 'f1-score': 0.8590019893899203, 'support': 324}, 'weighted avg': {'precision': 0.8734567901234568, 'recall': 0.8703703703703703, 'f1-score': 0.8713589252382357, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_6d86c23d-6455-4e03-b3fd-a6916b9daca5\", \"model_fold_3.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 4\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5724802175180508 Training Accuracy Score:  0.7076183939601922\n",
            "Validation Loss:  0.4562570537839617 Validation Accuracy Score:  0.7716049382716049 \n",
            " Classification Report:  {'0': {'precision': 0.7923728813559322, 'recall': 0.8820754716981132, 'f1-score': 0.8348214285714285, 'support': 212}, '1': {'precision': 0.7159090909090909, 'recall': 0.5625, 'f1-score': 0.63, 'support': 112}, 'accuracy': 0.7716049382716049, 'macro avg': {'precision': 0.7541409861325116, 'recall': 0.7222877358490566, 'f1-score': 0.7324107142857142, 'support': 324}, 'weighted avg': {'precision': 0.7659409537940611, 'recall': 0.7716049382716049, 'f1-score': 0.764018959435626, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.348187686234224 Training Accuracy Score:  0.853809196980096\n",
            "Validation Loss:  0.37573705187865664 Validation Accuracy Score:  0.8518518518518519 \n",
            " Classification Report:  {'0': {'precision': 0.8904761904761904, 'recall': 0.8820754716981132, 'f1-score': 0.886255924170616, 'support': 212}, '1': {'precision': 0.7807017543859649, 'recall': 0.7946428571428571, 'f1-score': 0.7876106194690264, 'support': 112}, 'accuracy': 0.8518518518518519, 'macro avg': {'precision': 0.8355889724310777, 'recall': 0.8383591644204851, 'f1-score': 0.8369332718198212, 'support': 324}, 'weighted avg': {'precision': 0.8525294718277174, 'recall': 0.8518518518518519, 'f1-score': 0.852156312668832, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.21784683402444496 Training Accuracy Score:  0.9169526424159231\n",
            "Validation Loss:  0.40645594540096464 Validation Accuracy Score:  0.8611111111111112 \n",
            " Classification Report:  {'0': {'precision': 0.8883720930232558, 'recall': 0.9009433962264151, 'f1-score': 0.8946135831381734, 'support': 212}, '1': {'precision': 0.8073394495412844, 'recall': 0.7857142857142857, 'f1-score': 0.7963800904977376, 'support': 112}, 'accuracy': 0.8611111111111112, 'macro avg': {'precision': 0.8478557712822701, 'recall': 0.8433288409703503, 'f1-score': 0.8454968368179555, 'support': 324}, 'weighted avg': {'precision': 0.8603608088566485, 'recall': 0.8611111111111112, 'f1-score': 0.8606563264229611, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.11452246371330947 Training Accuracy Score:  0.9588194921070693\n",
            "Validation Loss:  0.4155009239912033 Validation Accuracy Score:  0.8611111111111112 \n",
            " Classification Report:  {'0': {'precision': 0.9073170731707317, 'recall': 0.8773584905660378, 'f1-score': 0.8920863309352518, 'support': 212}, '1': {'precision': 0.7815126050420168, 'recall': 0.8303571428571429, 'f1-score': 0.8051948051948052, 'support': 112}, 'accuracy': 0.8611111111111112, 'macro avg': {'precision': 0.8444148391063743, 'recall': 0.8538578167115903, 'f1-score': 0.8486405680650285, 'support': 324}, 'weighted avg': {'precision': 0.8638291088793241, 'recall': 0.8611111111111112, 'f1-score': 0.8620497541360851, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_b31d4b21-ff11-488b-957e-8f74a8011c88\", \"model_fold_4.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 5\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.558394781715883 Training Accuracy Score:  0.7258064516129032\n",
            "Validation Loss:  0.4360947410265605 Validation Accuracy Score:  0.7993827160493827 \n",
            " Classification Report:  {'0': {'precision': 0.810126582278481, 'recall': 0.9056603773584906, 'f1-score': 0.8552338530066815, 'support': 212}, '1': {'precision': 0.7701149425287356, 'recall': 0.5982142857142857, 'f1-score': 0.6733668341708542, 'support': 112}, 'accuracy': 0.7993827160493827, 'macro avg': {'precision': 0.7901207624036083, 'recall': 0.7519373315363882, 'f1-score': 0.7643003435887679, 'support': 324}, 'weighted avg': {'precision': 0.7962953981674579, 'recall': 0.7993827160493827, 'f1-score': 0.7923662415572598, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.3197163604403454 Training Accuracy Score:  0.8647906657515443\n",
            "Validation Loss:  0.3612766900942439 Validation Accuracy Score:  0.8487654320987654 \n",
            " Classification Report:  {'0': {'precision': 0.9222797927461139, 'recall': 0.839622641509434, 'f1-score': 0.8790123456790123, 'support': 212}, '1': {'precision': 0.7404580152671756, 'recall': 0.8660714285714286, 'f1-score': 0.7983539094650205, 'support': 112}, 'accuracy': 0.8487654320987654, 'macro avg': {'precision': 0.8313689040066448, 'recall': 0.8528470350404314, 'f1-score': 0.8386831275720164, 'support': 324}, 'weighted avg': {'precision': 0.8594278202842588, 'recall': 0.8487654320987654, 'f1-score': 0.8511304171112127, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.18650943855118882 Training Accuracy Score:  0.9299931365820179\n",
            "Validation Loss:  0.28837374065603527 Validation Accuracy Score:  0.8858024691358025 \n",
            " Classification Report:  {'0': {'precision': 0.8959276018099548, 'recall': 0.9339622641509434, 'f1-score': 0.9145496535796768, 'support': 212}, '1': {'precision': 0.8640776699029126, 'recall': 0.7946428571428571, 'f1-score': 0.827906976744186, 'support': 112}, 'accuracy': 0.8858024691358025, 'macro avg': {'precision': 0.8800026358564337, 'recall': 0.8643025606469003, 'f1-score': 0.8712283151619313, 'support': 324}, 'weighted avg': {'precision': 0.8849177488050513, 'recall': 0.8858024691358025, 'f1-score': 0.8845990986241986, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.0966804627955082 Training Accuracy Score:  0.9680851063829787\n",
            "Validation Loss:  0.3061877269785674 Validation Accuracy Score:  0.8888888888888888 \n",
            " Classification Report:  {'0': {'precision': 0.919047619047619, 'recall': 0.910377358490566, 'f1-score': 0.9146919431279621, 'support': 212}, '1': {'precision': 0.8333333333333334, 'recall': 0.8482142857142857, 'f1-score': 0.84070796460177, 'support': 112}, 'accuracy': 0.8888888888888888, 'macro avg': {'precision': 0.8761904761904762, 'recall': 0.8792958221024259, 'f1-score': 0.877699953864866, 'support': 324}, 'weighted avg': {'precision': 0.8894179894179894, 'recall': 0.8888888888888888, 'f1-score': 0.889117234501624, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.04784302495399622 Training Accuracy Score:  0.9821551132463967\n",
            "Validation Loss:  0.3359552764976841 Validation Accuracy Score:  0.9104938271604939 \n",
            " Classification Report:  {'0': {'precision': 0.9255813953488372, 'recall': 0.9386792452830188, 'f1-score': 0.9320843091334895, 'support': 212}, '1': {'precision': 0.8807339449541285, 'recall': 0.8571428571428571, 'f1-score': 0.8687782805429863, 'support': 112}, 'accuracy': 0.9104938271604939, 'macro avg': {'precision': 0.9031576701514828, 'recall': 0.897911051212938, 'f1-score': 0.9004312948382379, 'support': 324}, 'weighted avg': {'precision': 0.9100785729901725, 'recall': 0.9104938271604939, 'f1-score': 0.910200743694797, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_dd702542-b92d-446e-8cf1-8e13f4ec15e9\", \"model_fold_5.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 6\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.533171220148196 Training Accuracy Score:  0.7237474262182567\n",
            "Validation Loss:  0.35783819996175315 Validation Accuracy Score:  0.8611111111111112 \n",
            " Classification Report:  {'0': {'precision': 0.8464730290456431, 'recall': 0.9622641509433962, 'f1-score': 0.9006622516556291, 'support': 212}, '1': {'precision': 0.9036144578313253, 'recall': 0.6696428571428571, 'f1-score': 0.7692307692307693, 'support': 112}, 'accuracy': 0.8611111111111112, 'macro avg': {'precision': 0.8750437434384842, 'recall': 0.8159535040431267, 'f1-score': 0.8349465104431992, 'support': 324}, 'weighted avg': {'precision': 0.8662256217122986, 'recall': 0.8611111111111112, 'f1-score': 0.8552291466198749, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.29400645538431697 Training Accuracy Score:  0.883321894303363\n",
            "Validation Loss:  0.3063910236316068 Validation Accuracy Score:  0.8703703703703703 \n",
            " Classification Report:  {'0': {'precision': 0.8728070175438597, 'recall': 0.9386792452830188, 'f1-score': 0.9045454545454547, 'support': 212}, '1': {'precision': 0.8645833333333334, 'recall': 0.7410714285714286, 'f1-score': 0.7980769230769232, 'support': 112}, 'accuracy': 0.8703703703703703, 'macro avg': {'precision': 0.8686951754385965, 'recall': 0.8398753369272237, 'f1-score': 0.851311188811189, 'support': 324}, 'weighted avg': {'precision': 0.8699642625081221, 'recall': 0.8703703703703703, 'f1-score': 0.8677415177415178, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.16174469841389708 Training Accuracy Score:  0.942347288949897\n",
            "Validation Loss:  0.312418961808795 Validation Accuracy Score:  0.8981481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.8908296943231441, 'recall': 0.9622641509433962, 'f1-score': 0.9251700680272109, 'support': 212}, '1': {'precision': 0.9157894736842105, 'recall': 0.7767857142857143, 'f1-score': 0.8405797101449276, 'support': 112}, 'accuracy': 0.8981481481481481, 'macro avg': {'precision': 0.9033095840036773, 'recall': 0.8695249326145553, 'f1-score': 0.8828748890860693, 'support': 324}, 'weighted avg': {'precision': 0.8994577662010435, 'recall': 0.8981481481481481, 'f1-score': 0.8959289566604957, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.09131880756722041 Training Accuracy Score:  0.967741935483871\n",
            "Validation Loss:  0.35294038177068743 Validation Accuracy Score:  0.8981481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.8841201716738197, 'recall': 0.9716981132075472, 'f1-score': 0.9258426966292135, 'support': 212}, '1': {'precision': 0.9340659340659341, 'recall': 0.7589285714285714, 'f1-score': 0.8374384236453202, 'support': 112}, 'accuracy': 0.8981481481481481, 'macro avg': {'precision': 0.9090930528698768, 'recall': 0.8653133423180592, 'f1-score': 0.8816405601372668, 'support': 324}, 'weighted avg': {'precision': 0.9013853734883779, 'recall': 0.8981481481481481, 'f1-score': 0.8952831948570035, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_34105c66-8c25-47e4-9776-584314d45126\", \"model_fold_6.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 7\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.546295168214157 Training Accuracy Score:  0.7240905971173645\n",
            "Validation Loss:  0.3713702665907996 Validation Accuracy Score:  0.8487654320987654 \n",
            " Classification Report:  {'0': {'precision': 0.8552631578947368, 'recall': 0.9241706161137441, 'f1-score': 0.8883826879271071, 'support': 211}, '1': {'precision': 0.8333333333333334, 'recall': 0.7079646017699115, 'f1-score': 0.7655502392344498, 'support': 113}, 'accuracy': 0.8487654320987654, 'macro avg': {'precision': 0.8442982456140351, 'recall': 0.8160676089418277, 'f1-score': 0.8269664635807784, 'support': 324}, 'weighted avg': {'precision': 0.8476147931557289, 'recall': 0.8487654320987654, 'f1-score': 0.845542975883063, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.29816516989567243 Training Accuracy Score:  0.880576527110501\n",
            "Validation Loss:  0.32288108659642084 Validation Accuracy Score:  0.8827160493827161 \n",
            " Classification Report:  {'0': {'precision': 0.9390862944162437, 'recall': 0.8767772511848341, 'f1-score': 0.9068627450980392, 'support': 211}, '1': {'precision': 0.7952755905511811, 'recall': 0.8938053097345132, 'f1-score': 0.8416666666666667, 'support': 113}, 'accuracy': 0.8827160493827161, 'macro avg': {'precision': 0.8671809424837125, 'recall': 0.8852912804596736, 'f1-score': 0.8742647058823529, 'support': 324}, 'weighted avg': {'precision': 0.8889300921423174, 'recall': 0.8827160493827161, 'f1-score': 0.8841246066327765, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.1636284858680488 Training Accuracy Score:  0.9426904598490048\n",
            "Validation Loss:  0.26178248612476246 Validation Accuracy Score:  0.9012345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.8977777777777778, 'recall': 0.957345971563981, 'f1-score': 0.9266055045871561, 'support': 211}, '1': {'precision': 0.9090909090909091, 'recall': 0.7964601769911505, 'f1-score': 0.8490566037735849, 'support': 113}, 'accuracy': 0.9012345679012346, 'macro avg': {'precision': 0.9034343434343435, 'recall': 0.8769030742775658, 'f1-score': 0.8878310541803704, 'support': 324}, 'weighted avg': {'precision': 0.9017234069085921, 'recall': 0.9012345679012346, 'f1-score': 0.8995591286861265, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.06880665850148746 Training Accuracy Score:  0.9773507206588882\n",
            "Validation Loss:  0.32167493851323214 Validation Accuracy Score:  0.8981481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.8869565217391304, 'recall': 0.966824644549763, 'f1-score': 0.9251700680272109, 'support': 211}, '1': {'precision': 0.925531914893617, 'recall': 0.7699115044247787, 'f1-score': 0.8405797101449276, 'support': 113}, 'accuracy': 0.8981481481481481, 'macro avg': {'precision': 0.9062442183163737, 'recall': 0.8683680744872708, 'f1-score': 0.8828748890860693, 'support': 324}, 'weighted avg': {'precision': 0.9004102854010346, 'recall': 0.8981481481481481, 'f1-score': 0.8956678753090072, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.04220811535650101 Training Accuracy Score:  0.9866163349347975\n",
            "Validation Loss:  0.3083080515775475 Validation Accuracy Score:  0.9074074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.9330143540669856, 'recall': 0.9241706161137441, 'f1-score': 0.9285714285714285, 'support': 211}, '1': {'precision': 0.8608695652173913, 'recall': 0.8761061946902655, 'f1-score': 0.8684210526315789, 'support': 113}, 'accuracy': 0.9074074074074074, 'macro avg': {'precision': 0.8969419596421885, 'recall': 0.9001384054020047, 'f1-score': 0.8984962406015037, 'support': 324}, 'weighted avg': {'precision': 0.9078527456101826, 'recall': 0.9074074074074074, 'f1-score': 0.9075930567158637, 'support': 324}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_05fcfa43-252f-4143-abe8-1a31996c11d3\", \"model_fold_7.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 8\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5556167866525754 Training Accuracy Score:  0.7166380789022299\n",
            "Validation Loss:  0.3903191164135933 Validation Accuracy Score:  0.826625386996904 \n",
            " Classification Report:  {'0': {'precision': 0.8215767634854771, 'recall': 0.9383886255924171, 'f1-score': 0.8761061946902655, 'support': 211}, '1': {'precision': 0.8414634146341463, 'recall': 0.6160714285714286, 'f1-score': 0.7113402061855669, 'support': 112}, 'accuracy': 0.826625386996904, 'macro avg': {'precision': 0.8315200890598118, 'recall': 0.7772300270819228, 'f1-score': 0.7937232004379162, 'support': 323}, 'weighted avg': {'precision': 0.8284724443791333, 'recall': 0.826625386996904, 'f1-score': 0.818973715704116, 'support': 323}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.3375569535164885 Training Accuracy Score:  0.8552315608919383\n",
            "Validation Loss:  0.3116122150704974 Validation Accuracy Score:  0.8606811145510835 \n",
            " Classification Report:  {'0': {'precision': 0.8429752066115702, 'recall': 0.966824644549763, 'f1-score': 0.9006622516556291, 'support': 211}, '1': {'precision': 0.9135802469135802, 'recall': 0.6607142857142857, 'f1-score': 0.7668393782383419, 'support': 112}, 'accuracy': 0.8606811145510835, 'macro avg': {'precision': 0.8782777267625752, 'recall': 0.8137694651320244, 'f1-score': 0.8337508149469854, 'support': 323}, 'weighted avg': {'precision': 0.8674574496884282, 'recall': 0.8606811145510835, 'f1-score': 0.8542592738762603, 'support': 323}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.20927032337732654 Training Accuracy Score:  0.9183533447684391\n",
            "Validation Loss:  0.2941105357770409 Validation Accuracy Score:  0.8823529411764706 \n",
            " Classification Report:  {'0': {'precision': 0.8844444444444445, 'recall': 0.943127962085308, 'f1-score': 0.9128440366972477, 'support': 211}, '1': {'precision': 0.8775510204081632, 'recall': 0.7678571428571429, 'f1-score': 0.819047619047619, 'support': 112}, 'accuracy': 0.8823529411764706, 'macro avg': {'precision': 0.8809977324263039, 'recall': 0.8554925524712255, 'f1-score': 0.8659458278724333, 'support': 323}, 'weighted avg': {'precision': 0.8820541549953316, 'recall': 0.8823529411764706, 'f1-score': 0.8803202014750855, 'support': 323}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.10948642502574484 Training Accuracy Score:  0.9643224699828473\n",
            "Validation Loss:  0.3957176728262788 Validation Accuracy Score:  0.8823529411764706 \n",
            " Classification Report:  {'0': {'precision': 0.8878923766816144, 'recall': 0.9383886255924171, 'f1-score': 0.912442396313364, 'support': 211}, '1': {'precision': 0.87, 'recall': 0.7767857142857143, 'f1-score': 0.820754716981132, 'support': 112}, 'accuracy': 0.8823529411764706, 'macro avg': {'precision': 0.8789461883408072, 'recall': 0.8575871699390657, 'f1-score': 0.866598556647248, 'support': 323}, 'weighted avg': {'precision': 0.8816882089158533, 'recall': 0.8823529411764706, 'f1-score': 0.8806497644706086, 'support': 323}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.05567785415574501 Training Accuracy Score:  0.9831903945111492\n",
            "Validation Loss:  0.3846048162363115 Validation Accuracy Score:  0.891640866873065 \n",
            " Classification Report:  {'0': {'precision': 0.9, 'recall': 0.9383886255924171, 'f1-score': 0.9187935034802784, 'support': 211}, '1': {'precision': 0.8737864077669902, 'recall': 0.8035714285714286, 'f1-score': 0.8372093023255814, 'support': 112}, 'accuracy': 0.891640866873065, 'macro avg': {'precision': 0.8868932038834951, 'recall': 0.8709800270819228, 'f1-score': 0.8780014029029299, 'support': 323}, 'weighted avg': {'precision': 0.890910457182362, 'recall': 0.891640866873065, 'f1-score': 0.8905042448755538, 'support': 323}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_54540e6a-4701-483f-9840-709a62ba80e9\", \"model_fold_8.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 9\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5527196298531496 Training Accuracy Score:  0.7234991423670669\n",
            "Validation Loss:  0.40526434921083 Validation Accuracy Score:  0.8452012383900929 \n",
            " Classification Report:  {'0': {'precision': 0.8546255506607929, 'recall': 0.919431279620853, 'f1-score': 0.8858447488584474, 'support': 211}, '1': {'precision': 0.8229166666666666, 'recall': 0.7053571428571429, 'f1-score': 0.7596153846153847, 'support': 112}, 'accuracy': 0.8452012383900929, 'macro avg': {'precision': 0.8387711086637297, 'recall': 0.8123942112389979, 'f1-score': 0.8227300667369161, 'support': 323}, 'weighted avg': {'precision': 0.8436305196783095, 'recall': 0.8452012383900929, 'f1-score': 0.8420748145079117, 'support': 323}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.2993032685964485 Training Accuracy Score:  0.8775300171526587\n",
            "Validation Loss:  0.303759023192383 Validation Accuracy Score:  0.8699690402476781 \n",
            " Classification Report:  {'0': {'precision': 0.8967136150234741, 'recall': 0.9052132701421801, 'f1-score': 0.9009433962264151, 'support': 211}, '1': {'precision': 0.8181818181818182, 'recall': 0.8035714285714286, 'f1-score': 0.8108108108108109, 'support': 112}, 'accuracy': 0.8699690402476781, 'macro avg': {'precision': 0.8574477166026462, 'recall': 0.8543923493568044, 'f1-score': 0.855877103518613, 'support': 323}, 'weighted avg': {'precision': 0.8694827752517545, 'recall': 0.8699690402476781, 'f1-score': 0.8696899919956174, 'support': 323}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.17268345745209138 Training Accuracy Score:  0.9365351629502573\n",
            "Validation Loss:  0.36424368974708377 Validation Accuracy Score:  0.8978328173374613 \n",
            " Classification Report:  {'0': {'precision': 0.9198113207547169, 'recall': 0.9241706161137441, 'f1-score': 0.921985815602837, 'support': 211}, '1': {'precision': 0.8558558558558559, 'recall': 0.8482142857142857, 'f1-score': 0.852017937219731, 'support': 112}, 'accuracy': 0.8978328173374613, 'macro avg': {'precision': 0.8878335883052864, 'recall': 0.8861924509140149, 'f1-score': 0.8870018764112839, 'support': 323}, 'weighted avg': {'precision': 0.8976348128021707, 'recall': 0.8978328173374613, 'f1-score': 0.8977245079281996, 'support': 323}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.09520236850090202 Training Accuracy Score:  0.9646655231560892\n",
            "Validation Loss:  0.33539793804465307 Validation Accuracy Score:  0.8885448916408669 \n",
            " Classification Report:  {'0': {'precision': 0.9032258064516129, 'recall': 0.9289099526066351, 'f1-score': 0.9158878504672897, 'support': 211}, '1': {'precision': 0.8584905660377359, 'recall': 0.8125, 'f1-score': 0.8348623853211008, 'support': 112}, 'accuracy': 0.8885448916408669, 'macro avg': {'precision': 0.8808581862446744, 'recall': 0.8707049763033176, 'f1-score': 0.8753751178941953, 'support': 323}, 'weighted avg': {'precision': 0.8877138964629, 'recall': 0.8885448916408669, 'f1-score': 0.887792333141057, 'support': 323}}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_01f9d133-0e8a-47f5-965d-76cfe2640af1\", \"model_fold_9.pth\", 435778273)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_losses, val_losses, precision_scores, recall_scores, f1_scores, class_reps, m_weights = train_and_eval_with_kfold(train_d, y_train, loss, me, min_delta, lr=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NEKDvaj_9s"
      },
      "source": [
        "## Average Measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00omaC2xky6h"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miDp5WipkGvS"
      },
      "source": [
        "### Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnAhQr4_k0hu"
      },
      "outputs": [],
      "source": [
        "with open('precision_scores.pkl', 'wb') as f:\n",
        "    pickle.dump(precision_scores, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udho9cm1kF-9",
        "outputId": "a5de3f6e-9268-449e-acc8-362a017e0de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0 Last Precision: 0.9081020936463963\n",
            "Fold 1 Last Precision: 0.8740695862904622\n",
            "Fold 2 Last Precision: 0.8983838383838384\n",
            "Fold 3 Last Precision: 0.8541666666666666\n",
            "Fold 4 Last Precision: 0.8444148391063743\n",
            "Fold 5 Last Precision: 0.9031576701514828\n",
            "Fold 6 Last Precision: 0.9090930528698768\n",
            "Fold 7 Last Precision: 0.8969419596421885\n",
            "Fold 8 Last Precision: 0.8868932038834951\n",
            "Fold 9 Last Precision: 0.8808581862446744\n"
          ]
        }
      ],
      "source": [
        "for k in precision_scores.keys():\n",
        "  print(f'Fold {k} Last Precision:', precision_scores[k][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMx6FKiS-ORL",
        "outputId": "587c3b89-58e4-4245-ba3a-c33ab89239cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8856081096885455"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_precision = np.mean([precision_scores[k][-1] for k in precision_scores.keys()])\n",
        "average_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la0er54wkmiC"
      },
      "source": [
        "### Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PzTY4Q7lIeL"
      },
      "outputs": [],
      "source": [
        "with open('recall_scores.pkl', 'wb') as f:\n",
        "    pickle.dump(recall_scores, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaSdmm7PjyY5",
        "outputId": "6415ad89-9fde-4eb1-ecd3-79019a9946d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0 Last Recall: 0.8784535040431267\n",
            "Fold 1 Last Recall: 0.8640498652291105\n",
            "Fold 2 Last Recall: 0.8737365229110512\n",
            "Fold 3 Last Recall: 0.8651448787061995\n",
            "Fold 4 Last Recall: 0.8538578167115903\n",
            "Fold 5 Last Recall: 0.897911051212938\n",
            "Fold 6 Last Recall: 0.8653133423180592\n",
            "Fold 7 Last Recall: 0.9001384054020047\n",
            "Fold 8 Last Recall: 0.8709800270819228\n",
            "Fold 9 Last Recall: 0.8707049763033176\n"
          ]
        }
      ],
      "source": [
        "for k in recall_scores.keys():\n",
        "  print(f'Fold {k} Last Recall:', recall_scores[k][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1vswkZ9lFB8",
        "outputId": "86a513b7-bbff-48cc-a0de-5395d0ae47e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8740290389919322"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_recall = np.mean([recall_scores[k][-1] for k in recall_scores.keys()])\n",
        "average_recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyNpMc6ElgRo"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OLLcbpNlTbO"
      },
      "outputs": [],
      "source": [
        "with open('f1_scores.pkl', 'wb') as f:\n",
        "    pickle.dump(f1_scores, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdKrgFBfllwU",
        "outputId": "8bdde830-d909-423b-8204-dff7adf9c45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0 Last F1: 0.8905298034898803\n",
            "Fold 1 Last F1: 0.8686579901856198\n",
            "Fold 2 Last F1: 0.8840435107963605\n",
            "Fold 3 Last F1: 0.8590019893899203\n",
            "Fold 4 Last F1: 0.8486405680650285\n",
            "Fold 5 Last F1: 0.9004312948382379\n",
            "Fold 6 Last F1: 0.8816405601372668\n",
            "Fold 7 Last F1: 0.8984962406015037\n",
            "Fold 8 Last F1: 0.8780014029029299\n",
            "Fold 9 Last F1: 0.8753751178941953\n"
          ]
        }
      ],
      "source": [
        "for k in f1_scores.keys():\n",
        "  print(f'Fold {k} Last F1:', f1_scores[k][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oidaTI4TlrY_",
        "outputId": "a7f61d85-670e-49ca-b795-db9137919b3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8784818478300943"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_f1 = np.mean([f1_scores[k][-1] for k in f1_scores.keys()])\n",
        "average_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byZdaeaFl0__"
      },
      "source": [
        "### Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a7eGjKLlvwl"
      },
      "outputs": [],
      "source": [
        "with open('val_losses.pkl', 'wb') as f:\n",
        "    pickle.dump(val_losses, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2mXcGQXl9R8",
        "outputId": "06cb8c9a-ff22-41b0-ce2a-574b5b2b876c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0 Last F1: 0.3228577315208635\n",
            "Fold 1 Last F1: 0.4555352165230683\n",
            "Fold 2 Last F1: 0.35314855054907857\n",
            "Fold 3 Last F1: 0.39620955820594517\n",
            "Fold 4 Last F1: 0.4155009239912033\n",
            "Fold 5 Last F1: 0.3359552764976841\n",
            "Fold 6 Last F1: 0.35294038177068743\n",
            "Fold 7 Last F1: 0.3083080515775475\n",
            "Fold 8 Last F1: 0.3846048162363115\n",
            "Fold 9 Last F1: 0.33539793804465307\n"
          ]
        }
      ],
      "source": [
        "for k in val_losses.keys():\n",
        "  print(f'Fold {k} Last F1:', val_losses[k][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrP-BPXNmCcR",
        "outputId": "8ac28126-f50f-417e-f37d-0f26491d73b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.36604584449170424"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_losses_average = np.mean([val_losses[k][-1] for k in val_losses.keys()])\n",
        "val_losses_average"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbSy3AQNmVIT"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "proQwuvqmIZs",
        "outputId": "2355f34c-0443-48c8-9b4d-ded929b0daad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0 = NpredModel(1)\n",
        "model_0.load_state_dict(torch.load('model_fold_0.pth'))\n",
        "model_0.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mVWV_E9_Tqp",
        "outputId": "46d9f86d-4cc0-4d4e-eb74-03603d7c55c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1 = NpredModel(1)\n",
        "model_1.load_state_dict(torch.load('model_fold_1.pth'))\n",
        "model_1.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRRQU0UI_WP3",
        "outputId": "5f9bc90d-28fc-4250-808d-feca4bac3a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2 = NpredModel(1)\n",
        "model_2.load_state_dict(torch.load('model_fold_2.pth'))\n",
        "model_2.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJf2-p9F_Z2D",
        "outputId": "f87d32d1-1d37-47fb-ea81-92287c3bdbaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_3 = NpredModel(1)\n",
        "model_3.load_state_dict(torch.load('model_fold_3.pth'))\n",
        "model_3.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjiqdw8F_dHp",
        "outputId": "888f1283-0d04-49b8-acf8-074675e8f8dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_4 = NpredModel(1)\n",
        "model_4.load_state_dict(torch.load('model_fold_4.pth'))\n",
        "model_4.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM_3GakzAUlE",
        "outputId": "cb52a847-ee4f-4a9e-ed77-e81b474c9a19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_5 = NpredModel(1)\n",
        "model_5.load_state_dict(torch.load('model_fold_5.pth'))\n",
        "model_5.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjl19SYuAZF9",
        "outputId": "3a1e3052-7e63-4192-c96c-bb5b52299ef0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_6 = NpredModel(1)\n",
        "model_6.load_state_dict(torch.load('model_fold_6.pth'))\n",
        "model_6.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7G3jlmdAbzF",
        "outputId": "cc9ccc06-d2ba-4449-9328-0bc30103a2be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_7 = NpredModel(1)\n",
        "model_7.load_state_dict(torch.load('model_fold_7.pth'))\n",
        "model_7.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhYgrZnpAezx",
        "outputId": "fab058d2-6b11-4388-fe99-decdaeea892e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_8 = NpredModel(1)\n",
        "model_8.load_state_dict(torch.load('model_fold_8.pth'))\n",
        "model_8.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TB8V1RKAhmx",
        "outputId": "b3938cdd-66bd-4e2e-e205-fc4117bf2c71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NpredModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_9 = NpredModel(1)\n",
        "model_9.load_state_dict(torch.load('model_fold_9.pth'))\n",
        "model_9.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEYJ7lNJR7S7"
      },
      "source": [
        "### Predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR32ViYmTf8J"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZHnMnHpRPvz"
      },
      "outputs": [],
      "source": [
        "preds_model_0 = []\n",
        "model_0.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  #preds_model_0.append(model_0(batch['x']).detach().numpy())\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_0(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_0.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx4ZsuOPUvEZ"
      },
      "outputs": [],
      "source": [
        "preds_model_1 = []\n",
        "model_1.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_1(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_1.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-jvhMcsTXcx"
      },
      "outputs": [],
      "source": [
        "preds_model_2 = []\n",
        "model_2.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_2(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_2.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqTK-0qYVHhF"
      },
      "outputs": [],
      "source": [
        "preds_model_3 = []\n",
        "model_3.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_3(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_3.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SemBc3JVVvG"
      },
      "outputs": [],
      "source": [
        "preds_model_4 = []\n",
        "model_4.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_4(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_4.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj25lIOmVZAM"
      },
      "outputs": [],
      "source": [
        "preds_model_5 = []\n",
        "model_5.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_5(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_5.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB0JbV4RVdVq"
      },
      "outputs": [],
      "source": [
        "preds_model_6 = []\n",
        "model_6.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_6(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_6.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5pR4JMoVkLD"
      },
      "outputs": [],
      "source": [
        "preds_model_7 = []\n",
        "model_7.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_7(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_7.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj7xCXqxVsdr"
      },
      "outputs": [],
      "source": [
        "preds_model_8 = []\n",
        "model_8.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_8(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_8.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VVuFBcvVxLJ"
      },
      "outputs": [],
      "source": [
        "preds_model_9 = []\n",
        "model_9.to(device)\n",
        "for i, batch in enumerate(test_dlr):\n",
        "  input_ids = batch['input_ids'].squeeze(1).to(device)\n",
        "  attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
        "  label = batch['labels'].reshape(-1, 1)\n",
        "  output = model_9(input_ids, attention_mask)\n",
        "  ypred = torch.round(output)\n",
        "  preds_model_9.extend(ypred.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra3aYDLxWRfD"
      },
      "outputs": [],
      "source": [
        "preds_model_0 = np.array(preds_model_0)\n",
        "preds_model_1 = np.array(preds_model_1)\n",
        "preds_model_2 = np.array(preds_model_2)\n",
        "preds_model_3 = np.array(preds_model_3)\n",
        "preds_model_4 = np.array(preds_model_4)\n",
        "preds_model_5 = np.array(preds_model_5)\n",
        "preds_model_6 = np.array(preds_model_6)\n",
        "preds_model_7 = np.array(preds_model_7)\n",
        "preds_model_8 = np.array(preds_model_8)\n",
        "preds_model_9 = np.array(preds_model_9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQzGpEa-VzrA"
      },
      "outputs": [],
      "source": [
        "final_preds = preds_model_0 + preds_model_1 + preds_model_2 + preds_model_3 + preds_model_4 + preds_model_5 + preds_model_6 + preds_model_7 + preds_model_8 + preds_model_9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB204irHV1_q"
      },
      "outputs": [],
      "source": [
        "final_preds = final_preds / 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkiXXJTxWfvf"
      },
      "outputs": [],
      "source": [
        "final_preds = np.round(final_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWX-YBW_WnIJ",
        "outputId": "11bb238f-a604-417b-ee9b-f10cfac829e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.70      0.68       530\n",
            "         1.0       0.35      0.31      0.33       280\n",
            "\n",
            "    accuracy                           0.57       810\n",
            "   macro avg       0.51      0.51      0.51       810\n",
            "weighted avg       0.55      0.57      0.56       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx1Z6vhNXBZj",
        "outputId": "5cbc27dc-4323-4e91-ae23-c7ef22be52ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.66      0.65       530\n",
            "         1.0       0.33      0.33      0.33       280\n",
            "\n",
            "    accuracy                           0.54       810\n",
            "   macro avg       0.49      0.49      0.49       810\n",
            "weighted avg       0.54      0.54      0.54       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NLfB_moXLPq",
        "outputId": "c8acee65-e407-4329-9828-cd1b31e984d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.69      0.66       530\n",
            "         1.0       0.29      0.24      0.26       280\n",
            "\n",
            "    accuracy                           0.53       810\n",
            "   macro avg       0.46      0.46      0.46       810\n",
            "weighted avg       0.51      0.53      0.52       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5fvbcWaXNKn",
        "outputId": "2f38a50d-cb19-4f43-ba66-240153775157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.63      0.64       530\n",
            "         1.0       0.34      0.36      0.35       280\n",
            "\n",
            "    accuracy                           0.54       810\n",
            "   macro avg       0.49      0.49      0.49       810\n",
            "weighted avg       0.54      0.54      0.54       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS7bDMbvXYCC",
        "outputId": "d80c63cb-a77c-4d06-a0ec-bcd592b412ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.60      0.63       530\n",
            "         1.0       0.34      0.39      0.37       280\n",
            "\n",
            "    accuracy                           0.53       810\n",
            "   macro avg       0.50      0.50      0.50       810\n",
            "weighted avg       0.55      0.53      0.54       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4lYZU5YXaR5",
        "outputId": "5b10ab76-2ffe-4fcc-8ae2-7383735b4b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.66      0.65       530\n",
            "         1.0       0.30      0.28      0.29       280\n",
            "\n",
            "    accuracy                           0.53       810\n",
            "   macro avg       0.47      0.47      0.47       810\n",
            "weighted avg       0.52      0.53      0.52       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vL1UoLuXb6A",
        "outputId": "8c79f643-4bea-4836-9461-db1bc134119c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.67      0.66       530\n",
            "         1.0       0.34      0.32      0.33       280\n",
            "\n",
            "    accuracy                           0.55       810\n",
            "   macro avg       0.50      0.50      0.50       810\n",
            "weighted avg       0.54      0.55      0.55       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2zTzV4vXd2R",
        "outputId": "c1ae4d48-23ff-4bc3-ba5f-97f31e59b092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.64      0.65       530\n",
            "         1.0       0.34      0.36      0.35       280\n",
            "\n",
            "    accuracy                           0.54       810\n",
            "   macro avg       0.50      0.50      0.50       810\n",
            "weighted avg       0.55      0.54      0.54       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NDsareBXfoG",
        "outputId": "fc08df63-236b-481b-c301-5958d012974f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.66      0.65       530\n",
            "         1.0       0.32      0.30      0.31       280\n",
            "\n",
            "    accuracy                           0.54       810\n",
            "   macro avg       0.48      0.48      0.48       810\n",
            "weighted avg       0.53      0.54      0.53       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaFFR3KwXhLg",
        "outputId": "9835c6b1-6ac6-4dc1-d9f4-6b379c90b98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.70      0.69       530\n",
            "         1.0       0.40      0.38      0.39       280\n",
            "\n",
            "    accuracy                           0.59       810\n",
            "   macro avg       0.54      0.54      0.54       810\n",
            "weighted avg       0.58      0.59      0.59       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, preds_model_9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG-4EuyeXitg",
        "outputId": "76d154e7-f560-4f09-d753-d4995c09f9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.92      0.76       530\n",
            "         1.0       0.28      0.06      0.10       280\n",
            "\n",
            "    accuracy                           0.62       810\n",
            "   macro avg       0.47      0.49      0.43       810\n",
            "weighted avg       0.52      0.62      0.53       810\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, final_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD0pQcQtXk2J",
        "outputId": "afd3a511-994d-41c4-f04f-47bc57eab284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.345679012345679"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(y_test)/len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzKBy9ifAUGx"
      },
      "source": [
        "## Performing Many Train-Test Splits and Training with Stratified K-Fold\n",
        "\n",
        "Trying to understand if the poor performance on test data is due to some specific characteristic of the training data from the split we made."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "U9PimZKKhu4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval_with_kfold_adapted(X, y, loss, me, min_delta, k=10, lr=2e-7, random_state=0, patience=2):\n",
        "\n",
        "  # declaring random seed\n",
        "  torch.manual_seed(random_state)\n",
        "\n",
        "  # declare kfold\n",
        "  skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
        "\n",
        "  # declaring device\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "  train_losses = {}\n",
        "  val_losses = {}\n",
        "  classification_reports = {}\n",
        "  train_data = {}\n",
        "  test_data = {}\n",
        "  best_model_weights = {}\n",
        "\n",
        "  for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
        "\n",
        "    train_index = train_index.astype(int)\n",
        "    val_index = val_index.astype(int)\n",
        "\n",
        "    print(f'Fold: {i}')\n",
        "\n",
        "    # creating data based on fold\n",
        "    train_d, test_d = X[train_index], X[val_index]\n",
        "    y_train, y_test = y[train_index], y[val_index]\n",
        "\n",
        "    train_data[i] = [train_d, y_train]\n",
        "    test_data[i] = [test_d, y_test]\n",
        "\n",
        "    # creating dataloader\n",
        "    train_ds = NpredDataset(train_d, y_train)\n",
        "    test_ds = NpredDataset(test_d, y_test)\n",
        "    train_dlr = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "    test_dlr = DataLoader(test_ds, batch_size=16, shuffle=True)\n",
        "\n",
        "    # declaring the model\n",
        "    m = NpredModel(1)\n",
        "    m.to(device)\n",
        "    best_train_losses = None\n",
        "    best_val_losses = None\n",
        "    best_class_rep = None\n",
        "\n",
        "    max_epochs = 100\n",
        "    min_val_loss = np.inf\n",
        "    best_model = None\n",
        "    patience = 2\n",
        "\n",
        "\n",
        "    for e in range(max_epochs):\n",
        "      print('Epoch: ', e, '\\n')\n",
        "      train_loss = train(m, train_dlr, lr, loss)\n",
        "      val_loss, class_rep = evaluate(m, test_dlr, loss)\n",
        "\n",
        "      # early stopping\n",
        "      if val_loss < min_val_loss:\n",
        "\n",
        "        # update lowest validation loss\n",
        "        min_val_loss = val_loss\n",
        "\n",
        "        # save best results\n",
        "        best_model = m.state_dict()\n",
        "        best_class_rep = class_rep\n",
        "        best_train_losses = train_loss\n",
        "        best_val_losses = val_loss\n",
        "\n",
        "        # reestablish patience\n",
        "        patience = patience\n",
        "\n",
        "      elif val_loss > (min_val_loss + min_delta):\n",
        "        patience -= 1\n",
        "        if patience == 0:\n",
        "\n",
        "          # torch.save(best_model, name)\n",
        "          # files.download(name)\n",
        "          break\n",
        "\n",
        "    train_losses[i] = best_train_losses\n",
        "    val_losses[i] = best_val_losses\n",
        "    classification_reports[i] = best_class_rep\n",
        "    best_model_weights[i] = best_model\n",
        "\n",
        "  # we will choose the best model based on the f1-score macro average\n",
        "  f1_scores = [classification_reports[i]['macro avg']['f1-score'] for i in classification_reports.keys()]\n",
        "  best_model_idx = np.argmax(f1_scores)\n",
        "\n",
        "  # getting the outputs for the chosen model\n",
        "  chosen_model = best_model_weights[best_model_idx]\n",
        "  name = 'results/model_fold_' + str(best_model_idx) + '_random_state' + str(random_state) + '.pth'\n",
        "  torch.save(best_model, name)\n",
        "\n",
        "  # saving outputs\n",
        "  chosen_class_rep = classification_reports[best_model_idx]\n",
        "  chosen_val_loss = val_losses[best_model_idx]\n",
        "  chosen_train_loss = train_losses[best_model_idx]\n",
        "  dict_name = 'results/class_rep_fold_' + str(best_model_idx) + '_random_state_' + str(random_state) + '.pkl'\n",
        "  with open(dict_name, 'wb') as f:\n",
        "    pickle.dump(chosen_class_rep, f)\n",
        "  losses = {'val_loss_fold_' + str(best_model_idx) + '_random_state_' + str(random_state): chosen_val_loss,\n",
        "            'train_loss_fold_' + str(best_model_idx) + '_random_state_' + str(random_state): chosen_train_loss}\n",
        "  dict_name_losses = 'results/losses_fold_' + str(best_model_idx) + '_random_state_' + str(random_state) + '.pkl'\n",
        "  with open(dict_name_losses, 'wb') as f:\n",
        "    pickle.dump(losses, f)\n",
        "\n",
        "  # saving data\n",
        "  chosen_train_d, chosen_ytrain = train_data[best_model_idx]\n",
        "  chosen_test_d, chosen_ytest = test_data[best_model_idx]\n",
        "  name_xtrain = 'xtrain_data_fold_' + str(best_model_idx) + '_random_state_' + str(random_state) + '.txt'\n",
        "  name_xtest = 'xval_data_fold_' + str(best_model_idx) + '_random_state_' + str(random_state) + '.txt'\n",
        "  name_ytrain = 'ytrain_data_fold_' + str(best_model_idx) + '_random_state_' + str(random_state) + '.txt'\n",
        "  name_ytest = 'yval_data_fold_' + str(best_model_idx) + '_random_state_' + str(random_state) + '.txt'\n",
        "  np.savetxt(\"results/\" + name_xtrain, chosen_train_d, fmt='%s')\n",
        "  np.savetxt(\"results/\" + name_xtest, chosen_test_d, fmt='%s')\n",
        "  np.savetxt(\"results/\" + name_ytrain, chosen_ytrain, fmt='%i')\n",
        "  np.savetxt(\"results/\" + name_ytest, chosen_ytest, fmt='%i')\n",
        "\n",
        "  return losses, chosen_class_rep, best_model_weights"
      ],
      "metadata": {
        "id": "qiCw4OJ-2wwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXcQxfzvXp19"
      },
      "outputs": [],
      "source": [
        "def many_splits_training(X, y, loss, me, min_delta, random_states, k=10, lr=2e-7):\n",
        "\n",
        "  rs_losses = {}\n",
        "  rs_class_rep = {}\n",
        "  rs_models = {}\n",
        "\n",
        "  for i, state in enumerate(random_states):\n",
        "\n",
        "    print('########### State Number', i, '###########')\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                test_size=0.2,\n",
        "                                                shuffle=True,\n",
        "                                                random_state=state,\n",
        "                                                stratify=y)\n",
        "\n",
        "    # saving data\n",
        "    name_xtrain = 'xtrain' + '_random_state_' + str(state) + '.txt'\n",
        "    name_xtest = 'xval'+ '_random_state_' + str(state) + '.txt'\n",
        "    name_ytrain = 'ytrain' + '_random_state_' + str(state) + '.txt'\n",
        "    name_ytest = 'yval' + '_random_state_' + str(state) + '.txt'\n",
        "    np.savetxt(\"results/\" + name_xtrain, x_train, fmt='%s')\n",
        "    np.savetxt(\"results/\" + name_xtest, x_test, fmt='%s')\n",
        "    np.savetxt(\"results/\" + name_ytrain, y_train, fmt='%i')\n",
        "    np.savetxt(\"results/\" + name_ytest, y_test, fmt='%i')\n",
        "\n",
        "    # runing stratified k-fold\n",
        "    losses, class_rep, m_weights = train_and_eval_with_kfold_adapted(x_train, y_train,\n",
        "                                                                               loss,\n",
        "                                                                               me,\n",
        "                                                                               min_delta,\n",
        "                                                                               random_state=state)\n",
        "\n",
        "    rs_losses[state] = losses\n",
        "    rs_class_rep[state] = class_rep\n",
        "    rs_models[state] = m_weights\n",
        "\n",
        "  return rs_losses, rs_class_rep, rs_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuA1JPINMqbK"
      },
      "outputs": [],
      "source": [
        "loss = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZEiNkW-Mszj"
      },
      "outputs": [],
      "source": [
        "me = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrtjgflSMuO1"
      },
      "outputs": [],
      "source": [
        "min_delta = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HCUhZuPNE4P"
      },
      "outputs": [],
      "source": [
        "random_states = [0, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKHlJsoPM3ws",
        "outputId": "7e0f8981-aaf4-415c-855e-64a660e76e10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4048,)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_2dxLMaM4fY",
        "outputId": "f0dd4c6a-5936-44de-ff15-ac70914fdfde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4048,)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm0-jMWxUDJO"
      },
      "outputs": [],
      "source": [
        "!mkdir results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5ecCDQPM8vP",
        "outputId": "b7999153-95f6-4d0d-9449-7d02c1828130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.634987398900621 Training Accuracy Score:  0.6588881262868909\n",
            "Validation Loss:  0.6226416812056587 Validation Accuracy Score:  0.6975308641975309 \n",
            " Classification Report:  {'0': {'precision': 0.696551724137931, 'recall': 0.9528301886792453, 'f1-score': 0.8047808764940239, 'support': 212}, '1': {'precision': 0.7058823529411765, 'recall': 0.21428571428571427, 'f1-score': 0.3287671232876712, 'support': 112}, 'accuracy': 0.6975308641975309, 'macro avg': {'precision': 0.7012170385395537, 'recall': 0.5835579514824798, 'f1-score': 0.5667739998908475, 'support': 324}, 'weighted avg': {'precision': 0.699777126687201, 'recall': 0.6975308641975309, 'f1-score': 0.6402329124226921, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.627454201543266 Training Accuracy Score:  0.6722717913520934\n",
            "Validation Loss:  0.6106743613878886 Validation Accuracy Score:  0.7191358024691358 \n",
            " Classification Report:  {'0': {'precision': 0.7050847457627119, 'recall': 0.9811320754716981, 'f1-score': 0.8205128205128205, 'support': 212}, '1': {'precision': 0.8620689655172413, 'recall': 0.22321428571428573, 'f1-score': 0.35460992907801414, 'support': 112}, 'accuracy': 0.7191358024691358, 'macro avg': {'precision': 0.7835768556399766, 'recall': 0.602173180592992, 'f1-score': 0.5875613747954174, 'support': 324}, 'weighted avg': {'precision': 0.7593508958013147, 'recall': 0.7191358024691358, 'f1-score': 0.6594599691526406, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6211618509123235 Training Accuracy Score:  0.6846259437199725\n",
            "Validation Loss:  0.609576404094696 Validation Accuracy Score:  0.7160493827160493 \n",
            " Classification Report:  {'0': {'precision': 0.7027027027027027, 'recall': 0.9811320754716981, 'f1-score': 0.8188976377952756, 'support': 212}, '1': {'precision': 0.8571428571428571, 'recall': 0.21428571428571427, 'f1-score': 0.34285714285714286, 'support': 112}, 'accuracy': 0.7160493827160493, 'macro avg': {'precision': 0.7799227799227799, 'recall': 0.5977088948787062, 'f1-score': 0.5808773903262092, 'support': 324}, 'weighted avg': {'precision': 0.7560894227560894, 'recall': 0.7160493827160493, 'f1-score': 0.6543404296685137, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.620344213937801 Training Accuracy Score:  0.6880576527110501\n",
            "Validation Loss:  0.6065815914244879 Validation Accuracy Score:  0.7098765432098766 \n",
            " Classification Report:  {'0': {'precision': 0.6966666666666667, 'recall': 0.9858490566037735, 'f1-score': 0.8164062499999999, 'support': 212}, '1': {'precision': 0.875, 'recall': 0.1875, 'f1-score': 0.3088235294117647, 'support': 112}, 'accuracy': 0.7098765432098766, 'macro avg': {'precision': 0.7858333333333334, 'recall': 0.5866745283018868, 'f1-score': 0.5626148897058822, 'support': 324}, 'weighted avg': {'precision': 0.758312757201646, 'recall': 0.7098765432098766, 'f1-score': 0.640945556463326, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6173856929351723 Training Accuracy Score:  0.6884008236101579\n",
            "Validation Loss:  0.6028669731957572 Validation Accuracy Score:  0.7253086419753086 \n",
            " Classification Report:  {'0': {'precision': 0.7084745762711865, 'recall': 0.9858490566037735, 'f1-score': 0.8244575936883629, 'support': 212}, '1': {'precision': 0.896551724137931, 'recall': 0.23214285714285715, 'f1-score': 0.3687943262411348, 'support': 112}, 'accuracy': 0.7253086419753086, 'macro avg': {'precision': 0.8025131502045588, 'recall': 0.6089959568733153, 'f1-score': 0.5966259599647489, 'support': 324}, 'weighted avg': {'precision': 0.773488898990555, 'recall': 0.7253086419753086, 'f1-score': 0.6669443654350001, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6109519563411754 Training Accuracy Score:  0.6952642415923129\n",
            "Validation Loss:  0.6061003123010907 Validation Accuracy Score:  0.7253086419753086 \n",
            " Classification Report:  {'0': {'precision': 0.7084745762711865, 'recall': 0.9858490566037735, 'f1-score': 0.8244575936883629, 'support': 212}, '1': {'precision': 0.896551724137931, 'recall': 0.23214285714285715, 'f1-score': 0.3687943262411348, 'support': 112}, 'accuracy': 0.7253086419753086, 'macro avg': {'precision': 0.8025131502045588, 'recall': 0.6089959568733153, 'f1-score': 0.5966259599647489, 'support': 324}, 'weighted avg': {'precision': 0.773488898990555, 'recall': 0.7253086419753086, 'f1-score': 0.6669443654350001, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6089377450487001 Training Accuracy Score:  0.6990391214824982\n",
            "Validation Loss:  0.6041733225186666 Validation Accuracy Score:  0.7314814814814815 \n",
            " Classification Report:  {'0': {'precision': 0.711864406779661, 'recall': 0.9905660377358491, 'f1-score': 0.8284023668639052, 'support': 212}, '1': {'precision': 0.9310344827586207, 'recall': 0.24107142857142858, 'f1-score': 0.3829787234042554, 'support': 112}, 'accuracy': 0.7314814814814815, 'macro avg': {'precision': 0.8214494447691408, 'recall': 0.6158187331536388, 'f1-score': 0.6056905451340803, 'support': 324}, 'weighted avg': {'precision': 0.7876269021797953, 'recall': 0.7314814814814815, 'f1-score': 0.6744287617173597, 'support': 324}}\n",
            "Fold: 4\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6817292287701466 Training Accuracy Score:  0.5775566231983528\n",
            "Validation Loss:  0.6658921241760254 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.658307210031348, 'recall': 0.9905660377358491, 'f1-score': 0.7909604519774011, 'support': 212}, '1': {'precision': 0.6, 'recall': 0.026785714285714284, 'f1-score': 0.05128205128205128, 'support': 112}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.629153605015674, 'recall': 0.5086758760107817, 'f1-score': 0.4211212516297262, 'support': 324}, 'weighted avg': {'precision': 0.6381516312550796, 'recall': 0.6574074074074074, 'f1-score': 0.5352691529716012, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6669890421335815 Training Accuracy Score:  0.6259437199725463\n",
            "Validation Loss:  0.6527096515610105 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6531624894975965 Training Accuracy Score:  0.648936170212766\n",
            "Validation Loss:  0.6459600357782274 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6427733002464628 Training Accuracy Score:  0.6557995881949211\n",
            "Validation Loss:  0.6395509299777803 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6367653057874878 Training Accuracy Score:  0.6537405628002745\n",
            "Validation Loss:  0.6317274485315595 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6312886238749561 Training Accuracy Score:  0.6547700754975978\n",
            "Validation Loss:  0.6216662668046498 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6261247176615918 Training Accuracy Score:  0.6557995881949211\n",
            "Validation Loss:  0.6116588995570228 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6207695648969849 Training Accuracy Score:  0.6602608098833219\n",
            "Validation Loss:  0.6099084899539039 Validation Accuracy Score:  0.6820987654320988 \n",
            " Classification Report:  {'0': {'precision': 0.6730158730158731, 'recall': 1.0, 'f1-score': 0.8045540796963947, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.08035714285714286, 'f1-score': 0.14876033057851243, 'support': 112}, 'accuracy': 0.6820987654320988, 'macro avg': {'precision': 0.8365079365079365, 'recall': 0.5401785714285714, 'f1-score': 0.4766572051374536, 'support': 324}, 'weighted avg': {'precision': 0.7860474230844602, 'recall': 0.6820987654320988, 'f1-score': 0.5778599441988551, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6139204539562184 Training Accuracy Score:  0.6695264241592312\n",
            "Validation Loss:  0.604090446517581 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6074217992727874 Training Accuracy Score:  0.6801647220315717\n",
            "Validation Loss:  0.6068108578523 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6030345787116087 Training Accuracy Score:  0.6870281400137268\n",
            "Validation Loss:  0.5863930469467526 Validation Accuracy Score:  0.7098765432098766 \n",
            " Classification Report:  {'0': {'precision': 0.6928104575163399, 'recall': 1.0, 'f1-score': 0.8185328185328186, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.16071428571428573, 'f1-score': 0.27692307692307694, 'support': 112}, 'accuracy': 0.7098765432098766, 'macro avg': {'precision': 0.8464052287581699, 'recall': 0.5803571428571429, 'f1-score': 0.5477279477279478, 'support': 324}, 'weighted avg': {'precision': 0.7989994351650124, 'recall': 0.7098765432098766, 'f1-score': 0.6313096979763647, 'support': 324}}\n",
            "Epoch:  11 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5970979792172791 Training Accuracy Score:  0.6901166781056967\n",
            "Validation Loss:  0.587422965537934 Validation Accuracy Score:  0.7191358024691358 \n",
            " Classification Report:  {'0': {'precision': 0.6996699669966997, 'recall': 1.0, 'f1-score': 0.8233009708737864, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.1875, 'f1-score': 0.3157894736842105, 'support': 112}, 'accuracy': 0.7191358024691358, 'macro avg': {'precision': 0.8498349834983498, 'recall': 0.59375, 'f1-score': 0.5695452222789985, 'support': 324}, 'weighted avg': {'precision': 0.8034877561830257, 'recall': 0.7191358024691358, 'f1-score': 0.647864897771217, 'support': 324}}\n",
            "Fold: 5\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.7011158352341157 Training Accuracy Score:  0.47803706245710365\n",
            "Validation Loss:  0.6864081990151178 Validation Accuracy Score:  0.5740740740740741 \n",
            " Classification Report:  {'0': {'precision': 0.6581196581196581, 'recall': 0.7264150943396226, 'f1-score': 0.6905829596412556, 'support': 212}, '1': {'precision': 0.35555555555555557, 'recall': 0.2857142857142857, 'f1-score': 0.31683168316831684, 'support': 112}, 'accuracy': 0.5740740740740741, 'macro avg': {'precision': 0.5068376068376068, 'recall': 0.5060646900269541, 'f1-score': 0.5037073214047862, 'support': 324}, 'weighted avg': {'precision': 0.5535295979740424, 'recall': 0.5740740740740741, 'f1-score': 0.5613849875271533, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6795988379280424 Training Accuracy Score:  0.5868222374742622\n",
            "Validation Loss:  0.6674419329279945 Validation Accuracy Score:  0.6604938271604939 \n",
            " Classification Report:  {'0': {'precision': 0.6583850931677019, 'recall': 1.0, 'f1-score': 0.7940074906367041, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.017857142857142856, 'f1-score': 0.03508771929824561, 'support': 112}, 'accuracy': 0.6604938271604939, 'macro avg': {'precision': 0.829192546583851, 'recall': 0.5089285714285714, 'f1-score': 0.41454760496747484, 'support': 324}, 'weighted avg': {'precision': 0.7764741967640518, 'recall': 0.6604938271604939, 'f1-score': 0.5316648536308172, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6641156963311909 Training Accuracy Score:  0.6475634866163349\n",
            "Validation Loss:  0.6581345739818755 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.653846925725051 Training Accuracy Score:  0.651681537405628\n",
            "Validation Loss:  0.6455452158337548 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6460244606752865 Training Accuracy Score:  0.6527110501029513\n",
            "Validation Loss:  0.6395272328740075 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6378665722784449 Training Accuracy Score:  0.6527110501029513\n",
            "Validation Loss:  0.6444297915413266 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6366897697657183 Training Accuracy Score:  0.6537405628002745\n",
            "Validation Loss:  0.6291571429797581 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6317366680812314 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.6262340744336446 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6253810739908062 Training Accuracy Score:  0.6592312971859986\n",
            "Validation Loss:  0.6226356540407453 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.624613487818202 Training Accuracy Score:  0.6612903225806451\n",
            "Validation Loss:  0.6157606613068354 Validation Accuracy Score:  0.6666666666666666 \n",
            " Classification Report:  {'0': {'precision': 0.6625, 'recall': 1.0, 'f1-score': 0.7969924812030075, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.03571428571428571, 'f1-score': 0.0689655172413793, 'support': 112}, 'accuracy': 0.6666666666666666, 'macro avg': {'precision': 0.83125, 'recall': 0.5178571428571429, 'f1-score': 0.4329789992221934, 'support': 324}, 'weighted avg': {'precision': 0.7791666666666667, 'recall': 0.6666666666666666, 'f1-score': 0.5453288393397285, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6158405425118618 Training Accuracy Score:  0.6654083733699382\n",
            "Validation Loss:  0.6250388934498742 Validation Accuracy Score:  0.691358024691358 \n",
            " Classification Report:  {'0': {'precision': 0.6794871794871795, 'recall': 1.0, 'f1-score': 0.8091603053435115, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.10714285714285714, 'f1-score': 0.19354838709677416, 'support': 112}, 'accuracy': 0.691358024691358, 'macro avg': {'precision': 0.8397435897435898, 'recall': 0.5535714285714286, 'f1-score': 0.5013543462201429, 'support': 324}, 'weighted avg': {'precision': 0.7902817347261791, 'recall': 0.691358024691358, 'f1-score': 0.5963561854557504, 'support': 324}}\n",
            "Fold: 6\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6839361685872729 Training Accuracy Score:  0.5652024708304736\n",
            "Validation Loss:  0.6736862432389032 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.6563467492260062, 'recall': 1.0, 'f1-score': 0.7925233644859814, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.008928571428571428, 'f1-score': 0.017699115044247787, 'support': 112}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.8281733746130031, 'recall': 0.5044642857142857, 'f1-score': 0.4051112397651146, 'support': 324}, 'weighted avg': {'precision': 0.7751404655429424, 'recall': 0.6574074074074074, 'f1-score': 0.5246828831974808, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6689015379368933 Training Accuracy Score:  0.6338366506520247\n",
            "Validation Loss:  0.6587800241651989 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6586960449896223 Training Accuracy Score:  0.6499656829100893\n",
            "Validation Loss:  0.644319304398128 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6521732670361878 Training Accuracy Score:  0.6509951956074125\n",
            "Validation Loss:  0.6404903786523002 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6467574681740641 Training Accuracy Score:  0.653054221002059\n",
            "Validation Loss:  0.6316147134417579 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6402084345374602 Training Accuracy Score:  0.6544269045984901\n",
            "Validation Loss:  0.6358527228945777 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6356754524460255 Training Accuracy Score:  0.6547700754975978\n",
            "Validation Loss:  0.6270552334331331 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.629905543692125 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.6276045271328518 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.626958375908638 Training Accuracy Score:  0.6564859299931366\n",
            "Validation Loss:  0.6242014070351919 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6246952735335449 Training Accuracy Score:  0.6575154426904598\n",
            "Validation Loss:  0.608603835105896 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6174061282084939 Training Accuracy Score:  0.6619766643788607\n",
            "Validation Loss:  0.6143165713264829 Validation Accuracy Score:  0.6666666666666666 \n",
            " Classification Report:  {'0': {'precision': 0.6625, 'recall': 1.0, 'f1-score': 0.7969924812030075, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.03571428571428571, 'f1-score': 0.0689655172413793, 'support': 112}, 'accuracy': 0.6666666666666666, 'macro avg': {'precision': 0.83125, 'recall': 0.5178571428571429, 'f1-score': 0.4329789992221934, 'support': 324}, 'weighted avg': {'precision': 0.7791666666666667, 'recall': 0.6666666666666666, 'f1-score': 0.5453288393397285, 'support': 324}}\n",
            "Fold: 7\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6730679804510106 Training Accuracy Score:  0.6269732326698696\n",
            "Validation Loss:  0.6638778788702828 Validation Accuracy Score:  0.6327160493827161 \n",
            " Classification Report:  {'0': {'precision': 0.6446540880503144, 'recall': 0.9715639810426541, 'f1-score': 0.7750472589792059, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6327160493827161, 'macro avg': {'precision': 0.3223270440251572, 'recall': 0.48578199052132703, 'f1-score': 0.38752362948960295, 'support': 324}, 'weighted avg': {'precision': 0.4198210264772109, 'recall': 0.6327160493827161, 'f1-score': 0.5047375668043594, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6596743360243208 Training Accuracy Score:  0.6437886067261496\n",
            "Validation Loss:  0.6545094620613825 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6522583254699499 Training Accuracy Score:  0.6520247083047358\n",
            "Validation Loss:  0.6509933812277657 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6479992511493912 Training Accuracy Score:  0.653054221002059\n",
            "Validation Loss:  0.6489420675096058 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6414875342546265 Training Accuracy Score:  0.6544269045984901\n",
            "Validation Loss:  0.6417209846632821 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6362955816130821 Training Accuracy Score:  0.6554564172958133\n",
            "Validation Loss:  0.6371526547840664 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6346930965699785 Training Accuracy Score:  0.6564859299931366\n",
            "Validation Loss:  0.627625204267956 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6322055087714898 Training Accuracy Score:  0.6554564172958133\n",
            "Validation Loss:  0.6200797231424422 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6286689129357781 Training Accuracy Score:  0.6564859299931366\n",
            "Validation Loss:  0.6161645579905737 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6213933602382576 Training Accuracy Score:  0.6592312971859986\n",
            "Validation Loss:  0.6185365148953029 Validation Accuracy Score:  0.6481481481481481 \n",
            " Classification Report:  {'0': {'precision': 0.6501547987616099, 'recall': 0.995260663507109, 'f1-score': 0.7865168539325843, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6481481481481481, 'macro avg': {'precision': 0.32507739938080493, 'recall': 0.4976303317535545, 'f1-score': 0.39325842696629215, 'support': 324}, 'weighted avg': {'precision': 0.4234032794404311, 'recall': 0.6481481481481481, 'f1-score': 0.5122069635178249, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6219697229849185 Training Accuracy Score:  0.6654083733699382\n",
            "Validation Loss:  0.6050341299601963 Validation Accuracy Score:  0.6759259259259259 \n",
            " Classification Report:  {'0': {'precision': 0.6687898089171974, 'recall': 0.995260663507109, 'f1-score': 0.7999999999999999, 'support': 211}, '1': {'precision': 0.9, 'recall': 0.07964601769911504, 'f1-score': 0.14634146341463417, 'support': 113}, 'accuracy': 0.6759259259259259, 'macro avg': {'precision': 0.7843949044585987, 'recall': 0.537453340603112, 'f1-score': 0.47317073170731705, 'support': 324}, 'weighted avg': {'precision': 0.7494279311158292, 'recall': 0.6759259259259259, 'f1-score': 0.5720264980427582, 'support': 324}}\n",
            "Epoch:  11 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6134842699342739 Training Accuracy Score:  0.67124227865477\n",
            "Validation Loss:  0.6151272242977506 Validation Accuracy Score:  0.6851851851851852 \n",
            " Classification Report:  {'0': {'precision': 0.6752411575562701, 'recall': 0.995260663507109, 'f1-score': 0.8045977011494253, 'support': 211}, '1': {'precision': 0.9230769230769231, 'recall': 0.10619469026548672, 'f1-score': 0.19047619047619047, 'support': 113}, 'accuracy': 0.6851851851851852, 'macro avg': {'precision': 0.7991590403165967, 'recall': 0.5507276768862979, 'f1-score': 0.4975369458128079, 'support': 324}, 'weighted avg': {'precision': 0.761677705407609, 'recall': 0.6851851851851852, 'f1-score': 0.5904133471183279, 'support': 324}}\n",
            "Fold: 8\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.705805019928458 Training Accuracy Score:  0.451114922813036\n",
            "Validation Loss:  0.673249968460628 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.7239819004524887, 'recall': 0.7582938388625592, 'f1-score': 0.7407407407407408, 'support': 211}, '1': {'precision': 0.5, 'recall': 0.45535714285714285, 'f1-score': 0.4766355140186916, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.6119909502262444, 'recall': 0.606825490859851, 'f1-score': 0.6086881273797162, 'support': 323}, 'weighted avg': {'precision': 0.6463163498311922, 'recall': 0.653250773993808, 'f1-score': 0.6491624577906804, 'support': 323}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6672441376362993 Training Accuracy Score:  0.62778730703259\n",
            "Validation Loss:  0.6405015559423537 Validation Accuracy Score:  0.6780185758513931 \n",
            " Classification Report:  {'0': {'precision': 0.6742671009771987, 'recall': 0.981042654028436, 'f1-score': 0.7992277992277992, 'support': 211}, '1': {'precision': 0.75, 'recall': 0.10714285714285714, 'f1-score': 0.1875, 'support': 112}, 'accuracy': 0.6780185758513931, 'macro avg': {'precision': 0.7121335504885993, 'recall': 0.5440927555856466, 'f1-score': 0.4933638996138996, 'support': 323}, 'weighted avg': {'precision': 0.7005274250965601, 'recall': 0.6780185758513931, 'f1-score': 0.5871116583190886, 'support': 323}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6489326325270648 Training Accuracy Score:  0.6689536878216124\n",
            "Validation Loss:  0.6357549883070446 Validation Accuracy Score:  0.6873065015479877 \n",
            " Classification Report:  {'0': {'precision': 0.6762820512820513, 'recall': 1.0, 'f1-score': 0.8068833652007649, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.09821428571428571, 'f1-score': 0.17886178861788615, 'support': 112}, 'accuracy': 0.6873065015479877, 'macro avg': {'precision': 0.8381410256410257, 'recall': 0.5491071428571429, 'f1-score': 0.4928725769093255, 'support': 323}, 'weighted avg': {'precision': 0.7885309994443122, 'recall': 0.6873065015479877, 'f1-score': 0.5891173696054633, 'support': 323}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6391892556935712 Training Accuracy Score:  0.6713550600343053\n",
            "Validation Loss:  0.636466593969436 Validation Accuracy Score:  0.6811145510835913 \n",
            " Classification Report:  {'0': {'precision': 0.6719745222929936, 'recall': 1.0, 'f1-score': 0.8038095238095238, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.08035714285714286, 'f1-score': 0.14876033057851243, 'support': 112}, 'accuracy': 0.6811145510835913, 'macro avg': {'precision': 0.8359872611464968, 'recall': 0.5401785714285714, 'f1-score': 0.4762849271940181, 'support': 323}, 'weighted avg': {'precision': 0.7857171027982094, 'recall': 0.6811145510835913, 'f1-score': 0.5766717230606901, 'support': 323}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6349578680562191 Training Accuracy Score:  0.674442538593482\n",
            "Validation Loss:  0.6217879085313707 Validation Accuracy Score:  0.6811145510835913 \n",
            " Classification Report:  {'0': {'precision': 0.6719745222929936, 'recall': 1.0, 'f1-score': 0.8038095238095238, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.08035714285714286, 'f1-score': 0.14876033057851243, 'support': 112}, 'accuracy': 0.6811145510835913, 'macro avg': {'precision': 0.8359872611464968, 'recall': 0.5401785714285714, 'f1-score': 0.4762849271940181, 'support': 323}, 'weighted avg': {'precision': 0.7857171027982094, 'recall': 0.6811145510835913, 'f1-score': 0.5766717230606901, 'support': 323}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6291055529495406 Training Accuracy Score:  0.6716981132075471\n",
            "Validation Loss:  0.6177991075175149 Validation Accuracy Score:  0.6811145510835913 \n",
            " Classification Report:  {'0': {'precision': 0.6719745222929936, 'recall': 1.0, 'f1-score': 0.8038095238095238, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.08035714285714286, 'f1-score': 0.14876033057851243, 'support': 112}, 'accuracy': 0.6811145510835913, 'macro avg': {'precision': 0.8359872611464968, 'recall': 0.5401785714285714, 'f1-score': 0.4762849271940181, 'support': 323}, 'weighted avg': {'precision': 0.7857171027982094, 'recall': 0.6811145510835913, 'f1-score': 0.5766717230606901, 'support': 323}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6244319141562519 Training Accuracy Score:  0.6785591766723842\n",
            "Validation Loss:  0.612715706938789 Validation Accuracy Score:  0.6811145510835913 \n",
            " Classification Report:  {'0': {'precision': 0.6719745222929936, 'recall': 1.0, 'f1-score': 0.8038095238095238, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.08035714285714286, 'f1-score': 0.14876033057851243, 'support': 112}, 'accuracy': 0.6811145510835913, 'macro avg': {'precision': 0.8359872611464968, 'recall': 0.5401785714285714, 'f1-score': 0.4762849271940181, 'support': 323}, 'weighted avg': {'precision': 0.7857171027982094, 'recall': 0.6811145510835913, 'f1-score': 0.5766717230606901, 'support': 323}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6192634706614447 Training Accuracy Score:  0.6847341337907376\n",
            "Validation Loss:  0.6146578845523653 Validation Accuracy Score:  0.6904024767801857 \n",
            " Classification Report:  {'0': {'precision': 0.6784565916398714, 'recall': 1.0, 'f1-score': 0.8084291187739463, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.10714285714285714, 'f1-score': 0.19354838709677416, 'support': 112}, 'accuracy': 0.6904024767801857, 'macro avg': {'precision': 0.8392282958199357, 'recall': 0.5535714285714286, 'f1-score': 0.5009887529353603, 'support': 323}, 'weighted avg': {'precision': 0.7899515196161389, 'recall': 0.6904024767801857, 'f1-score': 0.5952197009787658, 'support': 323}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6155885093199099 Training Accuracy Score:  0.683704974271012\n",
            "Validation Loss:  0.5971596354529971 Validation Accuracy Score:  0.6965944272445821 \n",
            " Classification Report:  {'0': {'precision': 0.6828478964401294, 'recall': 1.0, 'f1-score': 0.8115384615384615, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.125, 'f1-score': 0.2222222222222222, 'support': 112}, 'accuracy': 0.6965944272445821, 'macro avg': {'precision': 0.8414239482200647, 'recall': 0.5625, 'f1-score': 0.5168803418803418, 'support': 323}, 'weighted avg': {'precision': 0.7928201428757502, 'recall': 0.6965944272445821, 'f1-score': 0.6071935116826758, 'support': 323}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6075176196020158 Training Accuracy Score:  0.6936535162950257\n",
            "Validation Loss:  0.5930818134830111 Validation Accuracy Score:  0.6965944272445821 \n",
            " Classification Report:  {'0': {'precision': 0.6828478964401294, 'recall': 1.0, 'f1-score': 0.8115384615384615, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.125, 'f1-score': 0.2222222222222222, 'support': 112}, 'accuracy': 0.6965944272445821, 'macro avg': {'precision': 0.8414239482200647, 'recall': 0.5625, 'f1-score': 0.5168803418803418, 'support': 323}, 'weighted avg': {'precision': 0.7928201428757502, 'recall': 0.6965944272445821, 'f1-score': 0.6071935116826758, 'support': 323}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.604673015778182 Training Accuracy Score:  0.6946826758147513\n",
            "Validation Loss:  0.5895346743719918 Validation Accuracy Score:  0.6965944272445821 \n",
            " Classification Report:  {'0': {'precision': 0.6828478964401294, 'recall': 1.0, 'f1-score': 0.8115384615384615, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.125, 'f1-score': 0.2222222222222222, 'support': 112}, 'accuracy': 0.6965944272445821, 'macro avg': {'precision': 0.8414239482200647, 'recall': 0.5625, 'f1-score': 0.5168803418803418, 'support': 323}, 'weighted avg': {'precision': 0.7928201428757502, 'recall': 0.6965944272445821, 'f1-score': 0.6071935116826758, 'support': 323}}\n",
            "Epoch:  11 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.599654088417689 Training Accuracy Score:  0.6991423670668954\n",
            "Validation Loss:  0.5941976138523647 Validation Accuracy Score:  0.7089783281733746 \n",
            " Classification Report:  {'0': {'precision': 0.6918032786885245, 'recall': 1.0, 'f1-score': 0.8178294573643411, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.16071428571428573, 'f1-score': 0.27692307692307694, 'support': 112}, 'accuracy': 0.7089783281733746, 'macro avg': {'precision': 0.8459016393442622, 'recall': 0.5803571428571429, 'f1-score': 0.547376267143709, 'support': 323}, 'weighted avg': {'precision': 0.7986702532609248, 'recall': 0.7089783281733746, 'f1-score': 0.630270588604522, 'support': 323}}\n",
            "Fold: 9\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6789587224767508 Training Accuracy Score:  0.5910806174957118\n",
            "Validation Loss:  0.6662996127491906 Validation Accuracy Score:  0.6346749226006192 \n",
            " Classification Report:  {'0': {'precision': 0.6485623003194888, 'recall': 0.9620853080568721, 'f1-score': 0.7748091603053435, 'support': 211}, '1': {'precision': 0.2, 'recall': 0.017857142857142856, 'f1-score': 0.03278688524590164, 'support': 112}, 'accuracy': 0.6346749226006192, 'macro avg': {'precision': 0.42428115015974444, 'recall': 0.4899712254570075, 'f1-score': 0.4037980227756226, 'support': 323}, 'weighted avg': {'precision': 0.4930236698681491, 'recall': 0.6346749226006192, 'f1-score': 0.5175135107491284, 'support': 323}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6631933014249541 Training Accuracy Score:  0.6404802744425386\n",
            "Validation Loss:  0.6512806585856846 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6475663028779577 Training Accuracy Score:  0.6535162950257289\n",
            "Validation Loss:  0.6416567422094799 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6422152493169399 Training Accuracy Score:  0.6572898799313893\n",
            "Validation Loss:  0.6303458554404122 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6343479024582221 Training Accuracy Score:  0.6614065180102916\n",
            "Validation Loss:  0.6175545794623238 Validation Accuracy Score:  0.6563467492260062 \n",
            " Classification Report:  {'0': {'precision': 0.65527950310559, 'recall': 1.0, 'f1-score': 0.7917448405253283, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.008928571428571428, 'f1-score': 0.017699115044247787, 'support': 112}, 'accuracy': 0.6563467492260062, 'macro avg': {'precision': 0.827639751552795, 'recall': 0.5044642857142857, 'f1-score': 0.4047219777847881, 'support': 323}, 'weighted avg': {'precision': 0.7748110685921966, 'recall': 0.6563467492260062, 'f1-score': 0.5233450843213623, 'support': 323}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6276163196628862 Training Accuracy Score:  0.6710120068610634\n",
            "Validation Loss:  0.624690001919156 Validation Accuracy Score:  0.6965944272445821 \n",
            " Classification Report:  {'0': {'precision': 0.6828478964401294, 'recall': 1.0, 'f1-score': 0.8115384615384615, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.125, 'f1-score': 0.2222222222222222, 'support': 112}, 'accuracy': 0.6965944272445821, 'macro avg': {'precision': 0.8414239482200647, 'recall': 0.5625, 'f1-score': 0.5168803418803418, 'support': 323}, 'weighted avg': {'precision': 0.7928201428757502, 'recall': 0.6965944272445821, 'f1-score': 0.6071935116826758, 'support': 323}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.620440568103165 Training Accuracy Score:  0.6789022298456261\n",
            "Validation Loss:  0.6108870506286621 Validation Accuracy Score:  0.7027863777089783 \n",
            " Classification Report:  {'0': {'precision': 0.6872964169381107, 'recall': 1.0, 'f1-score': 0.8146718146718147, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7027863777089783, 'macro avg': {'precision': 0.8436482084690553, 'recall': 0.5714285714285714, 'f1-score': 0.5323359073359073, 'support': 323}, 'weighted avg': {'precision': 0.7957261423341838, 'recall': 0.7027863777089783, 'f1-score': 0.6188722999868511, 'support': 323}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6122110507201627 Training Accuracy Score:  0.6867924528301886\n",
            "Validation Loss:  0.6099613621121361 Validation Accuracy Score:  0.7120743034055728 \n",
            " Classification Report:  {'0': {'precision': 0.694078947368421, 'recall': 1.0, 'f1-score': 0.8194174757281553, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.16964285714285715, 'f1-score': 0.2900763358778626, 'support': 112}, 'accuracy': 0.7120743034055728, 'macro avg': {'precision': 0.8470394736842105, 'recall': 0.5848214285714286, 'f1-score': 0.5547469058030089, 'support': 323}, 'weighted avg': {'precision': 0.8001568355874205, 'recall': 0.7120743034055728, 'f1-score': 0.6358688451918308, 'support': 323}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6027313381270633 Training Accuracy Score:  0.6926243567753002\n",
            "Validation Loss:  0.5960573752721151 Validation Accuracy Score:  0.7120743034055728 \n",
            " Classification Report:  {'0': {'precision': 0.694078947368421, 'recall': 1.0, 'f1-score': 0.8194174757281553, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.16964285714285715, 'f1-score': 0.2900763358778626, 'support': 112}, 'accuracy': 0.7120743034055728, 'macro avg': {'precision': 0.8470394736842105, 'recall': 0.5848214285714286, 'f1-score': 0.5547469058030089, 'support': 323}, 'weighted avg': {'precision': 0.8001568355874205, 'recall': 0.7120743034055728, 'f1-score': 0.6358688451918308, 'support': 323}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5952499730339467 Training Accuracy Score:  0.7005145797598628\n",
            "Validation Loss:  0.5967392751148769 Validation Accuracy Score:  0.7151702786377709 \n",
            " Classification Report:  {'0': {'precision': 0.6963696369636964, 'recall': 1.0, 'f1-score': 0.821011673151751, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.17857142857142858, 'f1-score': 0.30303030303030304, 'support': 112}, 'accuracy': 0.7151702786377709, 'macro avg': {'precision': 0.8481848184818481, 'recall': 0.5892857142857143, 'f1-score': 0.5620209880910271, 'support': 323}, 'weighted avg': {'precision': 0.8016532303385137, 'recall': 0.7151702786377709, 'f1-score': 0.6414020339765121, 'support': 323}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5936975648494366 Training Accuracy Score:  0.700171526586621\n",
            "Validation Loss:  0.5764209911936805 Validation Accuracy Score:  0.7244582043343654 \n",
            " Classification Report:  {'0': {'precision': 0.7033333333333334, 'recall': 1.0, 'f1-score': 0.8258317025440314, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.20535714285714285, 'f1-score': 0.34074074074074073, 'support': 112}, 'accuracy': 0.7244582043343654, 'macro avg': {'precision': 0.8516666666666667, 'recall': 0.6026785714285714, 'f1-score': 0.5832862216423861, 'support': 323}, 'weighted avg': {'precision': 0.8062022703818369, 'recall': 0.7244582043343654, 'f1-score': 0.6576267869961411, 'support': 323}}\n",
            "Epoch:  11 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5852845688986648 Training Accuracy Score:  0.7084048027444254\n",
            "Validation Loss:  0.577580539953141 Validation Accuracy Score:  0.7275541795665634 \n",
            " Classification Report:  {'0': {'precision': 0.705685618729097, 'recall': 1.0, 'f1-score': 0.8274509803921568, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.21428571428571427, 'f1-score': 0.35294117647058826, 'support': 112}, 'accuracy': 0.7275541795665634, 'macro avg': {'precision': 0.8528428093645485, 'recall': 0.6071428571428571, 'f1-score': 0.5901960784313726, 'support': 323}, 'weighted avg': {'precision': 0.8077389026372739, 'recall': 0.7275541795665634, 'f1-score': 0.6629150731500031, 'support': 323}}\n",
            "########### State Number 1 ###########\n",
            "Fold: 0\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6699599337056686 Training Accuracy Score:  0.6135895676046671\n",
            "Validation Loss:  0.657791413012005 Validation Accuracy Score:  0.6450617283950617 \n",
            " Classification Report:  {'0': {'precision': 0.6529968454258676, 'recall': 0.9764150943396226, 'f1-score': 0.7826086956521741, 'support': 212}, '1': {'precision': 0.2857142857142857, 'recall': 0.017857142857142856, 'f1-score': 0.03361344537815126, 'support': 112}, 'accuracy': 0.6450617283950617, 'macro avg': {'precision': 0.4693555655700766, 'recall': 0.49713611859838275, 'f1-score': 0.40811107051516265, 'support': 324}, 'weighted avg': {'precision': 0.5260349729329751, 'recall': 0.6450617283950617, 'f1-score': 0.5236967572858452, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6572443885229976 Training Accuracy Score:  0.6413864104323953\n",
            "Validation Loss:  0.6469763545762925 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.6573208722741433, 'recall': 0.9952830188679245, 'f1-score': 0.7917448405253283, 'support': 212}, '1': {'precision': 0.6666666666666666, 'recall': 0.017857142857142856, 'f1-score': 0.034782608695652174, 'support': 112}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.661993769470405, 'recall': 0.5065700808625336, 'f1-score': 0.41326372461049027, 'support': 324}, 'weighted avg': {'precision': 0.6605515172493365, 'recall': 0.6574074074074074, 'f1-score': 0.5300788838434649, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6475276852566036 Training Accuracy Score:  0.6523678792038435\n",
            "Validation Loss:  0.6413666889781043 Validation Accuracy Score:  0.6604938271604939 \n",
            " Classification Report:  {'0': {'precision': 0.6583850931677019, 'recall': 1.0, 'f1-score': 0.7940074906367041, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.017857142857142856, 'f1-score': 0.03508771929824561, 'support': 112}, 'accuracy': 0.6604938271604939, 'macro avg': {'precision': 0.829192546583851, 'recall': 0.5089285714285714, 'f1-score': 0.41454760496747484, 'support': 324}, 'weighted avg': {'precision': 0.7764741967640518, 'recall': 0.6604938271604939, 'f1-score': 0.5316648536308172, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6440947733290209 Training Accuracy Score:  0.6547700754975978\n",
            "Validation Loss:  0.6322923217500959 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.6563467492260062, 'recall': 1.0, 'f1-score': 0.7925233644859814, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.008928571428571428, 'f1-score': 0.017699115044247787, 'support': 112}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.8281733746130031, 'recall': 0.5044642857142857, 'f1-score': 0.4051112397651146, 'support': 324}, 'weighted avg': {'precision': 0.7751404655429424, 'recall': 0.6574074074074074, 'f1-score': 0.5246828831974808, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6338345730890993 Training Accuracy Score:  0.6547700754975978\n",
            "Validation Loss:  0.6277699839501154 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6301331352340719 Training Accuracy Score:  0.6551132463967055\n",
            "Validation Loss:  0.6322161072776431 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6237321502523996 Training Accuracy Score:  0.6564859299931366\n",
            "Validation Loss:  0.6191856548899696 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6207554047224951 Training Accuracy Score:  0.6633493479752917\n",
            "Validation Loss:  0.6032301513921647 Validation Accuracy Score:  0.6975308641975309 \n",
            " Classification Report:  {'0': {'precision': 0.6838709677419355, 'recall': 1.0, 'f1-score': 0.8122605363984674, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.125, 'f1-score': 0.2222222222222222, 'support': 112}, 'accuracy': 0.6975308641975309, 'macro avg': {'precision': 0.8419354838709677, 'recall': 0.5625, 'f1-score': 0.5172413793103448, 'support': 324}, 'weighted avg': {'precision': 0.7931501393866985, 'recall': 0.6975308641975309, 'f1-score': 0.6082966747079135, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6114638182309156 Training Accuracy Score:  0.6739876458476322\n",
            "Validation Loss:  0.6006902612390972 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6023076437210124 Training Accuracy Score:  0.6925188743994509\n",
            "Validation Loss:  0.5946923011825198 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5980673798772155 Training Accuracy Score:  0.6935483870967742\n",
            "Validation Loss:  0.5889093010198503 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  11 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5903612274289782 Training Accuracy Score:  0.698009608785175\n",
            "Validation Loss:  0.5827846896080744 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  12 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.584334128378519 Training Accuracy Score:  0.7021276595744681\n",
            "Validation Loss:  0.5749743850458235 Validation Accuracy Score:  0.7067901234567902 \n",
            " Classification Report:  {'0': {'precision': 0.6918032786885245, 'recall': 0.9952830188679245, 'f1-score': 0.8162475822050289, 'support': 212}, '1': {'precision': 0.9473684210526315, 'recall': 0.16071428571428573, 'f1-score': 0.2748091603053435, 'support': 112}, 'accuracy': 0.7067901234567902, 'macro avg': {'precision': 0.819585849870578, 'recall': 0.5779986522911051, 'f1-score': 0.5455283712551862, 'support': 324}, 'weighted avg': {'precision': 0.780146784690932, 'recall': 0.7067901234567902, 'f1-score': 0.6290836832767426, 'support': 324}}\n",
            "Epoch:  13 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5820919229684631 Training Accuracy Score:  0.7069320521619766\n",
            "Validation Loss:  0.5751807930923644 Validation Accuracy Score:  0.7067901234567902 \n",
            " Classification Report:  {'0': {'precision': 0.6918032786885245, 'recall': 0.9952830188679245, 'f1-score': 0.8162475822050289, 'support': 212}, '1': {'precision': 0.9473684210526315, 'recall': 0.16071428571428573, 'f1-score': 0.2748091603053435, 'support': 112}, 'accuracy': 0.7067901234567902, 'macro avg': {'precision': 0.819585849870578, 'recall': 0.5779986522911051, 'f1-score': 0.5455283712551862, 'support': 324}, 'weighted avg': {'precision': 0.780146784690932, 'recall': 0.7067901234567902, 'f1-score': 0.6290836832767426, 'support': 324}}\n",
            "Epoch:  14 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5707829413843937 Training Accuracy Score:  0.7089910775566232\n",
            "Validation Loss:  0.5641639729340872 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6920529801324503, 'recall': 0.9858490566037735, 'f1-score': 0.8132295719844358, 'support': 212}, '1': {'precision': 0.8636363636363636, 'recall': 0.16964285714285715, 'f1-score': 0.2835820895522388, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.777844671884407, 'recall': 0.5777459568733153, 'f1-score': 0.5484058307683373, 'support': 324}, 'weighted avg': {'precision': 0.7513657546770129, 'recall': 0.7037037037037037, 'f1-score': 0.6301415533658985, 'support': 324}}\n",
            "Epoch:  15 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5677858550366157 Training Accuracy Score:  0.7086479066575154\n",
            "Validation Loss:  0.5541971042042687 Validation Accuracy Score:  0.7129629629629629 \n",
            " Classification Report:  {'0': {'precision': 0.6989966555183946, 'recall': 0.9858490566037735, 'f1-score': 0.8180039138943248, 'support': 212}, '1': {'precision': 0.88, 'recall': 0.19642857142857142, 'f1-score': 0.3211678832116788, 'support': 112}, 'accuracy': 0.7129629629629629, 'macro avg': {'precision': 0.7894983277591974, 'recall': 0.5911388140161725, 'f1-score': 0.5695858985530018, 'support': 324}, 'weighted avg': {'precision': 0.7615657128700607, 'recall': 0.7129629629629629, 'f1-score': 0.6462581255102002, 'support': 324}}\n",
            "Epoch:  16 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5580386522689152 Training Accuracy Score:  0.7230610844200411\n",
            "Validation Loss:  0.5546931439921969 Validation Accuracy Score:  0.7222222222222222 \n",
            " Classification Report:  {'0': {'precision': 0.706081081081081, 'recall': 0.9858490566037735, 'f1-score': 0.8228346456692913, 'support': 212}, '1': {'precision': 0.8928571428571429, 'recall': 0.22321428571428573, 'f1-score': 0.35714285714285715, 'support': 112}, 'accuracy': 0.7222222222222222, 'macro avg': {'precision': 0.799469111969112, 'recall': 0.6045316711590296, 'f1-score': 0.5899887514060742, 'support': 324}, 'weighted avg': {'precision': 0.7706456456456455, 'recall': 0.7222222222222222, 'f1-score': 0.6618547681539807, 'support': 324}}\n",
            "Epoch:  17 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5545340077798875 Training Accuracy Score:  0.727522306108442\n",
            "Validation Loss:  0.5431319432599204 Validation Accuracy Score:  0.7345679012345679 \n",
            " Classification Report:  {'0': {'precision': 0.7157534246575342, 'recall': 0.9858490566037735, 'f1-score': 0.8293650793650794, 'support': 212}, '1': {'precision': 0.90625, 'recall': 0.25892857142857145, 'f1-score': 0.40277777777777785, 'support': 112}, 'accuracy': 0.7345679012345679, 'macro avg': {'precision': 0.8110017123287672, 'recall': 0.6223888140161725, 'f1-score': 0.6160714285714286, 'support': 324}, 'weighted avg': {'precision': 0.781604092677152, 'recall': 0.7345679012345679, 'f1-score': 0.6819028022731727, 'support': 324}}\n",
            "Epoch:  18 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5464043695418561 Training Accuracy Score:  0.7354152367879204\n",
            "Validation Loss:  0.5435611378578913 Validation Accuracy Score:  0.7469135802469136 \n",
            " Classification Report:  {'0': {'precision': 0.7304964539007093, 'recall': 0.9716981132075472, 'f1-score': 0.8340080971659919, 'support': 212}, '1': {'precision': 0.8571428571428571, 'recall': 0.32142857142857145, 'f1-score': 0.4675324675324676, 'support': 112}, 'accuracy': 0.7469135802469136, 'macro avg': {'precision': 0.7938196555217831, 'recall': 0.6465633423180593, 'f1-score': 0.6507702823492297, 'support': 324}, 'weighted avg': {'precision': 0.7742754574905876, 'recall': 0.7469135802469136, 'f1-score': 0.7073251634655143, 'support': 324}}\n",
            "Epoch:  19 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5412046622708847 Training Accuracy Score:  0.7395332875772135\n",
            "Validation Loss:  0.5347336445535932 Validation Accuracy Score:  0.7561728395061729 \n",
            " Classification Report:  {'0': {'precision': 0.7366548042704626, 'recall': 0.9764150943396226, 'f1-score': 0.8397565922920892, 'support': 212}, '1': {'precision': 0.8837209302325582, 'recall': 0.3392857142857143, 'f1-score': 0.4903225806451613, 'support': 112}, 'accuracy': 0.7561728395061729, 'macro avg': {'precision': 0.8101878672515104, 'recall': 0.6578504043126685, 'f1-score': 0.6650395864686253, 'support': 324}, 'weighted avg': {'precision': 0.787492477442545, 'recall': 0.7561728395061729, 'f1-score': 0.7189645882659906, 'support': 324}}\n",
            "Epoch:  20 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5380978776457531 Training Accuracy Score:  0.7453671928620453\n",
            "Validation Loss:  0.5314036366485414 Validation Accuracy Score:  0.7561728395061729 \n",
            " Classification Report:  {'0': {'precision': 0.7383512544802867, 'recall': 0.9716981132075472, 'f1-score': 0.8391038696537678, 'support': 212}, '1': {'precision': 0.8666666666666667, 'recall': 0.3482142857142857, 'f1-score': 0.4968152866242038, 'support': 112}, 'accuracy': 0.7561728395061729, 'macro avg': {'precision': 0.8025089605734768, 'recall': 0.6599561994609164, 'f1-score': 0.6679595781389858, 'support': 324}, 'weighted avg': {'precision': 0.7827071994336032, 'recall': 0.7561728395061729, 'f1-score': 0.7207818903349061, 'support': 324}}\n",
            "Epoch:  21 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5266871452331543 Training Accuracy Score:  0.7546328071379547\n",
            "Validation Loss:  0.5338685356435322 Validation Accuracy Score:  0.7685185185185185 \n",
            " Classification Report:  {'0': {'precision': 0.7472924187725631, 'recall': 0.9764150943396226, 'f1-score': 0.8466257668711656, 'support': 212}, '1': {'precision': 0.8936170212765957, 'recall': 0.375, 'f1-score': 0.5283018867924528, 'support': 112}, 'accuracy': 0.7685185185185185, 'macro avg': {'precision': 0.8204547200245794, 'recall': 0.6757075471698113, 'f1-score': 0.6874638268318092, 'support': 324}, 'weighted avg': {'precision': 0.7978737628480311, 'recall': 0.7685185185185185, 'f1-score': 0.7365878823995119, 'support': 324}}\n",
            "Fold: 1\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6681584699557779 Training Accuracy Score:  0.6314344543582704\n",
            "Validation Loss:  0.6592990018072582 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6539585316767458 Training Accuracy Score:  0.6533973919011667\n",
            "Validation Loss:  0.6501903732617696 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6501096568472399 Training Accuracy Score:  0.6533973919011667\n",
            "Validation Loss:  0.636683987719672 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6430104185974663 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.6427301509039742 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6385675906483593 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.631194015343984 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6334835370707381 Training Accuracy Score:  0.6544269045984901\n",
            "Validation Loss:  0.6266202727953593 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6301856902453418 Training Accuracy Score:  0.6557995881949211\n",
            "Validation Loss:  0.6179054847785405 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6264887559609335 Training Accuracy Score:  0.6547700754975978\n",
            "Validation Loss:  0.6127015011651176 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6218053003152212 Training Accuracy Score:  0.6571722717913521\n",
            "Validation Loss:  0.6112065599078224 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6162271730886782 Training Accuracy Score:  0.6633493479752917\n",
            "Validation Loss:  0.612790530636197 Validation Accuracy Score:  0.6820987654320988 \n",
            " Classification Report:  {'0': {'precision': 0.6730158730158731, 'recall': 1.0, 'f1-score': 0.8045540796963947, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.08035714285714286, 'f1-score': 0.14876033057851243, 'support': 112}, 'accuracy': 0.6820987654320988, 'macro avg': {'precision': 0.8365079365079365, 'recall': 0.5401785714285714, 'f1-score': 0.4766572051374536, 'support': 324}, 'weighted avg': {'precision': 0.7860474230844602, 'recall': 0.6820987654320988, 'f1-score': 0.5778599441988551, 'support': 324}}\n",
            "Fold: 2\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.7129711398010046 Training Accuracy Score:  0.42141386410432397\n",
            "Validation Loss:  0.6953720308485485 Validation Accuracy Score:  0.5154320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.6395939086294417, 'recall': 0.5943396226415094, 'f1-score': 0.6161369193154034, 'support': 212}, '1': {'precision': 0.3228346456692913, 'recall': 0.36607142857142855, 'f1-score': 0.34309623430962344, 'support': 112}, 'accuracy': 0.5154320987654321, 'macro avg': {'precision': 0.4812142771493665, 'recall': 0.480205525606469, 'f1-score': 0.4796165768125134, 'support': 324}, 'weighted avg': {'precision': 0.5300968794580316, 'recall': 0.5154320987654321, 'f1-score': 0.5217524849924177, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6869748879651554 Training Accuracy Score:  0.5470144131777626\n",
            "Validation Loss:  0.6736436599776858 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.6551724137931034, 'recall': 0.9858490566037735, 'f1-score': 0.7871939736346516, 'support': 212}, '1': {'precision': 0.4, 'recall': 0.017857142857142856, 'f1-score': 0.034188034188034185, 'support': 112}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.5275862068965518, 'recall': 0.5018530997304582, 'f1-score': 0.4106910039113429, 'support': 324}, 'weighted avg': {'precision': 0.5669646658152406, 'recall': 0.6512345679012346, 'f1-score': 0.5268956241963146, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6677060143543723 Training Accuracy Score:  0.632120796156486\n",
            "Validation Loss:  0.6568640981401715 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 0.9952830188679245, 'f1-score': 0.788785046728972, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.49764150943396224, 'f1-score': 0.394392523364486, 'support': 324}, 'weighted avg': {'precision': 0.4274356916255781, 'recall': 0.6512345679012346, 'f1-score': 0.5161186108226606, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6514893486851552 Training Accuracy Score:  0.6537405628002745\n",
            "Validation Loss:  0.6441339311145601 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6445488359758763 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.6440550230798268 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6392403056061333 Training Accuracy Score:  0.6551132463967055\n",
            "Validation Loss:  0.6392005653608412 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6349244137279323 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.6294871426763988 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6312462335727254 Training Accuracy Score:  0.6544269045984901\n",
            "Validation Loss:  0.6193561412039257 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.624679565103979 Training Accuracy Score:  0.6544269045984901\n",
            "Validation Loss:  0.6147124682153974 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6192577717408456 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.620345447744642 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6146226611619439 Training Accuracy Score:  0.6582017844886754\n",
            "Validation Loss:  0.6093986857505072 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  11 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6103459526606596 Training Accuracy Score:  0.6609471516815374\n",
            "Validation Loss:  0.5984872593766167 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.6563467492260062, 'recall': 1.0, 'f1-score': 0.7925233644859814, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.008928571428571428, 'f1-score': 0.017699115044247787, 'support': 112}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.8281733746130031, 'recall': 0.5044642857142857, 'f1-score': 0.4051112397651146, 'support': 324}, 'weighted avg': {'precision': 0.7751404655429424, 'recall': 0.6574074074074074, 'f1-score': 0.5246828831974808, 'support': 324}}\n",
            "Epoch:  12 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6049083152103946 Training Accuracy Score:  0.6633493479752917\n",
            "Validation Loss:  0.6050711671511332 Validation Accuracy Score:  0.6697530864197531 \n",
            " Classification Report:  {'0': {'precision': 0.664576802507837, 'recall': 1.0, 'f1-score': 0.7984934086629003, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.044642857142857144, 'f1-score': 0.08547008547008547, 'support': 112}, 'accuracy': 0.6697530864197531, 'macro avg': {'precision': 0.8322884012539185, 'recall': 0.5223214285714286, 'f1-score': 0.4419817470664929, 'support': 324}, 'weighted avg': {'precision': 0.7805255621347575, 'recall': 0.6697530864197531, 'f1-score': 0.5520162105221742, 'support': 324}}\n",
            "Fold: 3\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.704284337374682 Training Accuracy Score:  0.45847632120796156\n",
            "Validation Loss:  0.6882666150728861 Validation Accuracy Score:  0.5864197530864198 \n",
            " Classification Report:  {'0': {'precision': 0.819672131147541, 'recall': 0.4716981132075472, 'f1-score': 0.5988023952095808, 'support': 212}, '1': {'precision': 0.44554455445544555, 'recall': 0.8035714285714286, 'f1-score': 0.5732484076433122, 'support': 112}, 'accuracy': 0.5864197530864198, 'macro avg': {'precision': 0.6326083428014933, 'recall': 0.6376347708894878, 'f1-score': 0.5860254014264465, 'support': 324}, 'weighted avg': {'precision': 0.6903440799453352, 'recall': 0.5864197530864198, 'f1-score': 0.5899689180261792, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6808167093438529 Training Accuracy Score:  0.5868222374742622\n",
            "Validation Loss:  0.6672652250244504 Validation Accuracy Score:  0.6944444444444444 \n",
            " Classification Report:  {'0': {'precision': 0.6840390879478827, 'recall': 0.9905660377358491, 'f1-score': 0.8092485549132948, 'support': 212}, '1': {'precision': 0.8823529411764706, 'recall': 0.13392857142857142, 'f1-score': 0.23255813953488372, 'support': 112}, 'accuracy': 0.6944444444444444, 'macro avg': {'precision': 0.7831960145621766, 'recall': 0.5622473045822103, 'f1-score': 0.5209033472240893, 'support': 324}, 'weighted avg': {'precision': 0.7525920248664069, 'recall': 0.6944444444444444, 'f1-score': 0.6098987816960663, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6642040681969272 Training Accuracy Score:  0.6465339739190117\n",
            "Validation Loss:  0.6501067507834661 Validation Accuracy Score:  0.6666666666666666 \n",
            " Classification Report:  {'0': {'precision': 0.6625, 'recall': 1.0, 'f1-score': 0.7969924812030075, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.03571428571428571, 'f1-score': 0.0689655172413793, 'support': 112}, 'accuracy': 0.6666666666666666, 'macro avg': {'precision': 0.83125, 'recall': 0.5178571428571429, 'f1-score': 0.4329789992221934, 'support': 324}, 'weighted avg': {'precision': 0.7791666666666667, 'recall': 0.6666666666666666, 'f1-score': 0.5453288393397285, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6522710577386325 Training Accuracy Score:  0.6595744680851063\n",
            "Validation Loss:  0.6460886484100705 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.642814296190856 Training Accuracy Score:  0.6606039807824297\n",
            "Validation Loss:  0.6266624175366902 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6363594971719335 Training Accuracy Score:  0.6616334934797529\n",
            "Validation Loss:  0.6192949102038429 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6296783482116428 Training Accuracy Score:  0.6633493479752917\n",
            "Validation Loss:  0.6169197275525048 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.6563467492260062, 'recall': 1.0, 'f1-score': 0.7925233644859814, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.008928571428571428, 'f1-score': 0.017699115044247787, 'support': 112}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.8281733746130031, 'recall': 0.5044642857142857, 'f1-score': 0.4051112397651146, 'support': 324}, 'weighted avg': {'precision': 0.7751404655429424, 'recall': 0.6574074074074074, 'f1-score': 0.5246828831974808, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6275993232192889 Training Accuracy Score:  0.6691832532601235\n",
            "Validation Loss:  0.6128472444557008 Validation Accuracy Score:  0.6882716049382716 \n",
            " Classification Report:  {'0': {'precision': 0.6773162939297125, 'recall': 1.0, 'f1-score': 0.8076190476190477, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.09821428571428571, 'f1-score': 0.17886178861788615, 'support': 112}, 'accuracy': 0.6882716049382716, 'macro avg': {'precision': 0.8386581469648562, 'recall': 0.5491071428571429, 'f1-score': 0.4932404181184669, 'support': 324}, 'weighted avg': {'precision': 0.7888612787441329, 'recall': 0.6882716049382716, 'f1-score': 0.5902708593223499, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6200414811327157 Training Accuracy Score:  0.6719286204529856\n",
            "Validation Loss:  0.6139029945646014 Validation Accuracy Score:  0.6882716049382716 \n",
            " Classification Report:  {'0': {'precision': 0.6773162939297125, 'recall': 1.0, 'f1-score': 0.8076190476190477, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.09821428571428571, 'f1-score': 0.17886178861788615, 'support': 112}, 'accuracy': 0.6882716049382716, 'macro avg': {'precision': 0.8386581469648562, 'recall': 0.5491071428571429, 'f1-score': 0.4932404181184669, 'support': 324}, 'weighted avg': {'precision': 0.7888612787441329, 'recall': 0.6882716049382716, 'f1-score': 0.5902708593223499, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.618007612358677 Training Accuracy Score:  0.6794783802333562\n",
            "Validation Loss:  0.5994499836649213 Validation Accuracy Score:  0.6882716049382716 \n",
            " Classification Report:  {'0': {'precision': 0.6773162939297125, 'recall': 1.0, 'f1-score': 0.8076190476190477, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.09821428571428571, 'f1-score': 0.17886178861788615, 'support': 112}, 'accuracy': 0.6882716049382716, 'macro avg': {'precision': 0.8386581469648562, 'recall': 0.5491071428571429, 'f1-score': 0.4932404181184669, 'support': 324}, 'weighted avg': {'precision': 0.7888612787441329, 'recall': 0.6882716049382716, 'f1-score': 0.5902708593223499, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6083678456603504 Training Accuracy Score:  0.6866849691146191\n",
            "Validation Loss:  0.6021742394992283 Validation Accuracy Score:  0.6882716049382716 \n",
            " Classification Report:  {'0': {'precision': 0.6773162939297125, 'recall': 1.0, 'f1-score': 0.8076190476190477, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.09821428571428571, 'f1-score': 0.17886178861788615, 'support': 112}, 'accuracy': 0.6882716049382716, 'macro avg': {'precision': 0.8386581469648562, 'recall': 0.5491071428571429, 'f1-score': 0.4932404181184669, 'support': 324}, 'weighted avg': {'precision': 0.7888612787441329, 'recall': 0.6882716049382716, 'f1-score': 0.5902708593223499, 'support': 324}}\n",
            "Fold: 4\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6705122384868685 Training Accuracy Score:  0.6197666437886067\n",
            "Validation Loss:  0.654927480788458 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6570813747051635 Training Accuracy Score:  0.6482498284145505\n",
            "Validation Loss:  0.6450931259563991 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6458988775972461 Training Accuracy Score:  0.6527110501029513\n",
            "Validation Loss:  0.6401463065828595 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6387029286942195 Training Accuracy Score:  0.6557995881949211\n",
            "Validation Loss:  0.630259150550479 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6332325347460033 Training Accuracy Score:  0.6554564172958133\n",
            "Validation Loss:  0.6246803629966009 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6275767698639729 Training Accuracy Score:  0.6571722717913521\n",
            "Validation Loss:  0.6230170059771765 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6244824769718399 Training Accuracy Score:  0.6599176389842142\n",
            "Validation Loss:  0.6267658032122112 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6206928822186475 Training Accuracy Score:  0.6606039807824297\n",
            "Validation Loss:  0.6111865951901391 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6153131990484852 Training Accuracy Score:  0.6636925188743995\n",
            "Validation Loss:  0.612245282956532 Validation Accuracy Score:  0.6697530864197531 \n",
            " Classification Report:  {'0': {'precision': 0.664576802507837, 'recall': 1.0, 'f1-score': 0.7984934086629003, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.044642857142857144, 'f1-score': 0.08547008547008547, 'support': 112}, 'accuracy': 0.6697530864197531, 'macro avg': {'precision': 0.8322884012539185, 'recall': 0.5223214285714286, 'f1-score': 0.4419817470664929, 'support': 324}, 'weighted avg': {'precision': 0.7805255621347575, 'recall': 0.6697530864197531, 'f1-score': 0.5520162105221742, 'support': 324}}\n",
            "Fold: 5\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6585902158028442 Training Accuracy Score:  0.6482498284145505\n",
            "Validation Loss:  0.6466323335965475 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6519803144241292 Training Accuracy Score:  0.6533973919011667\n",
            "Validation Loss:  0.6442754552477882 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6426262989070246 Training Accuracy Score:  0.6537405628002745\n",
            "Validation Loss:  0.634074520497095 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6379088163375854 Training Accuracy Score:  0.6533973919011667\n",
            "Validation Loss:  0.6304274343308949 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6348043089030219 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.6260850741749718 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6322620631567116 Training Accuracy Score:  0.6551132463967055\n",
            "Validation Loss:  0.6205516627856663 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6245940010078618 Training Accuracy Score:  0.6540837336993823\n",
            "Validation Loss:  0.6198524208295912 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6265886253346511 Training Accuracy Score:  0.6554564172958133\n",
            "Validation Loss:  0.6005364571298871 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.619035736784909 Training Accuracy Score:  0.6582017844886754\n",
            "Validation Loss:  0.6103346035594032 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6158831783982573 Training Accuracy Score:  0.6585449553877831\n",
            "Validation Loss:  0.5925748717217219 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.610603747797794 Training Accuracy Score:  0.6623198352779684\n",
            "Validation Loss:  0.5882457906291598 Validation Accuracy Score:  0.691358024691358 \n",
            " Classification Report:  {'0': {'precision': 0.6794871794871795, 'recall': 1.0, 'f1-score': 0.8091603053435115, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.10714285714285714, 'f1-score': 0.19354838709677416, 'support': 112}, 'accuracy': 0.691358024691358, 'macro avg': {'precision': 0.8397435897435898, 'recall': 0.5535714285714286, 'f1-score': 0.5013543462201429, 'support': 324}, 'weighted avg': {'precision': 0.7902817347261791, 'recall': 0.691358024691358, 'f1-score': 0.5963561854557504, 'support': 324}}\n",
            "Epoch:  11 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6079411537595134 Training Accuracy Score:  0.6678105696636926\n",
            "Validation Loss:  0.5819555960950398 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  12 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6019152533161184 Training Accuracy Score:  0.6760466712422787\n",
            "Validation Loss:  0.5777945660409474 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  13 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5987339933387569 Training Accuracy Score:  0.6774193548387096\n",
            "Validation Loss:  0.5763773009890601 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  14 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5948879414243124 Training Accuracy Score:  0.6877144818119424\n",
            "Validation Loss:  0.5745995938777924 Validation Accuracy Score:  0.7037037037037037 \n",
            " Classification Report:  {'0': {'precision': 0.6883116883116883, 'recall': 1.0, 'f1-score': 0.8153846153846155, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7037037037037037, 'macro avg': {'precision': 0.8441558441558441, 'recall': 0.5714285714285714, 'f1-score': 0.5326923076923078, 'support': 324}, 'weighted avg': {'precision': 0.7960557960557961, 'recall': 0.7037037037037037, 'f1-score': 0.61994301994302, 'support': 324}}\n",
            "Epoch:  15 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5896990121713753 Training Accuracy Score:  0.6904598490048044\n",
            "Validation Loss:  0.5629367700644902 Validation Accuracy Score:  0.7098765432098766 \n",
            " Classification Report:  {'0': {'precision': 0.6928104575163399, 'recall': 1.0, 'f1-score': 0.8185328185328186, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.16071428571428573, 'f1-score': 0.27692307692307694, 'support': 112}, 'accuracy': 0.7098765432098766, 'macro avg': {'precision': 0.8464052287581699, 'recall': 0.5803571428571429, 'f1-score': 0.5477279477279478, 'support': 324}, 'weighted avg': {'precision': 0.7989994351650124, 'recall': 0.7098765432098766, 'f1-score': 0.6313096979763647, 'support': 324}}\n",
            "Epoch:  16 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5842433811211195 Training Accuracy Score:  0.6921757035003432\n",
            "Validation Loss:  0.5545960664749146 Validation Accuracy Score:  0.7129629629629629 \n",
            " Classification Report:  {'0': {'precision': 0.6950819672131148, 'recall': 1.0, 'f1-score': 0.8201160541586073, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.16964285714285715, 'f1-score': 0.2900763358778626, 'support': 112}, 'accuracy': 0.7129629629629629, 'macro avg': {'precision': 0.8475409836065574, 'recall': 0.5848214285714286, 'f1-score': 0.5550961950182349, 'support': 324}, 'weighted avg': {'precision': 0.8004857316332726, 'recall': 0.7129629629629629, 'f1-score': 0.6368924478393375, 'support': 324}}\n",
            "Epoch:  17 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.5771159106265 Training Accuracy Score:  0.6973232669869595\n",
            "Validation Loss:  0.5611522524129777 Validation Accuracy Score:  0.7129629629629629 \n",
            " Classification Report:  {'0': {'precision': 0.6950819672131148, 'recall': 1.0, 'f1-score': 0.8201160541586073, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.16964285714285715, 'f1-score': 0.2900763358778626, 'support': 112}, 'accuracy': 0.7129629629629629, 'macro avg': {'precision': 0.8475409836065574, 'recall': 0.5848214285714286, 'f1-score': 0.5550961950182349, 'support': 324}, 'weighted avg': {'precision': 0.8004857316332726, 'recall': 0.7129629629629629, 'f1-score': 0.6368924478393375, 'support': 324}}\n",
            "Fold: 6\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.675969885346668 Training Accuracy Score:  0.6029512697323267\n",
            "Validation Loss:  0.6692536246208918 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.6563467492260062, 'recall': 1.0, 'f1-score': 0.7925233644859814, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.008928571428571428, 'f1-score': 0.017699115044247787, 'support': 112}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.8281733746130031, 'recall': 0.5044642857142857, 'f1-score': 0.4051112397651146, 'support': 324}, 'weighted avg': {'precision': 0.7751404655429424, 'recall': 0.6574074074074074, 'f1-score': 0.5246828831974808, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6600393008013241 Training Accuracy Score:  0.6554564172958133\n",
            "Validation Loss:  0.6556780622118995 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.649946691885672 Training Accuracy Score:  0.6592312971859986\n",
            "Validation Loss:  0.6437586091813587 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6450616837850686 Training Accuracy Score:  0.6664378860672615\n",
            "Validation Loss:  0.6320973393462953 Validation Accuracy Score:  0.654320987654321 \n",
            " Classification Report:  {'0': {'precision': 0.654320987654321, 'recall': 1.0, 'f1-score': 0.791044776119403, 'support': 212}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.654320987654321, 'macro avg': {'precision': 0.3271604938271605, 'recall': 0.5, 'f1-score': 0.3955223880597015, 'support': 324}, 'weighted avg': {'precision': 0.42813595488492606, 'recall': 0.654320987654321, 'f1-score': 0.517597199189239, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6334490355898122 Training Accuracy Score:  0.6736444749485244\n",
            "Validation Loss:  0.6286336666061765 Validation Accuracy Score:  0.6790123456790124 \n",
            " Classification Report:  {'0': {'precision': 0.6708860759493671, 'recall': 1.0, 'f1-score': 0.8030303030303031, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.07142857142857142, 'f1-score': 0.13333333333333333, 'support': 112}, 'accuracy': 0.6790123456790124, 'macro avg': {'precision': 0.8354430379746836, 'recall': 0.5357142857142857, 'f1-score': 0.4681818181818182, 'support': 324}, 'weighted avg': {'precision': 0.7846538521644008, 'recall': 0.6790123456790124, 'f1-score': 0.5715301159745605, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6252603140033659 Training Accuracy Score:  0.6859986273164036\n",
            "Validation Loss:  0.6260227404889607 Validation Accuracy Score:  0.6790123456790124 \n",
            " Classification Report:  {'0': {'precision': 0.6708860759493671, 'recall': 1.0, 'f1-score': 0.8030303030303031, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.07142857142857142, 'f1-score': 0.13333333333333333, 'support': 112}, 'accuracy': 0.6790123456790124, 'macro avg': {'precision': 0.8354430379746836, 'recall': 0.5357142857142857, 'f1-score': 0.4681818181818182, 'support': 324}, 'weighted avg': {'precision': 0.7846538521644008, 'recall': 0.6790123456790124, 'f1-score': 0.5715301159745605, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6176561022716793 Training Accuracy Score:  0.6901166781056967\n",
            "Validation Loss:  0.6274545164335341 Validation Accuracy Score:  0.6790123456790124 \n",
            " Classification Report:  {'0': {'precision': 0.6708860759493671, 'recall': 1.0, 'f1-score': 0.8030303030303031, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.07142857142857142, 'f1-score': 0.13333333333333333, 'support': 112}, 'accuracy': 0.6790123456790124, 'macro avg': {'precision': 0.8354430379746836, 'recall': 0.5357142857142857, 'f1-score': 0.4681818181818182, 'support': 324}, 'weighted avg': {'precision': 0.7846538521644008, 'recall': 0.6790123456790124, 'f1-score': 0.5715301159745605, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6129836423800943 Training Accuracy Score:  0.6942347288949897\n",
            "Validation Loss:  0.6079543346450442 Validation Accuracy Score:  0.6790123456790124 \n",
            " Classification Report:  {'0': {'precision': 0.6708860759493671, 'recall': 1.0, 'f1-score': 0.8030303030303031, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.07142857142857142, 'f1-score': 0.13333333333333333, 'support': 112}, 'accuracy': 0.6790123456790124, 'macro avg': {'precision': 0.8354430379746836, 'recall': 0.5357142857142857, 'f1-score': 0.4681818181818182, 'support': 324}, 'weighted avg': {'precision': 0.7846538521644008, 'recall': 0.6790123456790124, 'f1-score': 0.5715301159745605, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6070510613136604 Training Accuracy Score:  0.6959505833905285\n",
            "Validation Loss:  0.6079213420550028 Validation Accuracy Score:  0.6944444444444444 \n",
            " Classification Report:  {'0': {'precision': 0.6816720257234726, 'recall': 1.0, 'f1-score': 0.8107074569789675, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.11607142857142858, 'f1-score': 0.208, 'support': 112}, 'accuracy': 0.6944444444444444, 'macro avg': {'precision': 0.8408360128617363, 'recall': 0.5580357142857143, 'f1-score': 0.5093537284894838, 'support': 324}, 'weighted avg': {'precision': 0.7917113254733833, 'recall': 0.6944444444444444, 'f1-score': 0.6023641385171022, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6011170759552815 Training Accuracy Score:  0.699382292381606\n",
            "Validation Loss:  0.6100186364991325 Validation Accuracy Score:  0.6975308641975309 \n",
            " Classification Report:  {'0': {'precision': 0.6838709677419355, 'recall': 1.0, 'f1-score': 0.8122605363984674, 'support': 212}, '1': {'precision': 1.0, 'recall': 0.125, 'f1-score': 0.2222222222222222, 'support': 112}, 'accuracy': 0.6975308641975309, 'macro avg': {'precision': 0.8419354838709677, 'recall': 0.5625, 'f1-score': 0.5172413793103448, 'support': 324}, 'weighted avg': {'precision': 0.7931501393866985, 'recall': 0.6975308641975309, 'f1-score': 0.6082966747079135, 'support': 324}}\n",
            "Fold: 7\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6990017675962604 Training Accuracy Score:  0.48798901853122856\n",
            "Validation Loss:  0.684111754099528 Validation Accuracy Score:  0.6018518518518519 \n",
            " Classification Report:  {'0': {'precision': 0.6626984126984127, 'recall': 0.7914691943127962, 'f1-score': 0.7213822894168466, 'support': 211}, '1': {'precision': 0.3888888888888889, 'recall': 0.24778761061946902, 'f1-score': 0.30270270270270266, 'support': 113}, 'accuracy': 0.6018518518518519, 'macro avg': {'precision': 0.5257936507936508, 'recall': 0.5196284024661326, 'f1-score': 0.5120424960597746, 'support': 324}, 'weighted avg': {'precision': 0.5672031158142269, 'recall': 0.6018518518518519, 'f1-score': 0.5753613224455556, 'support': 324}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6735941731864638 Training Accuracy Score:  0.608098833218943\n",
            "Validation Loss:  0.6587696217355274 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.6512345679012346, 'recall': 1.0, 'f1-score': 0.788785046728972, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.3256172839506173, 'recall': 0.5, 'f1-score': 0.394392523364486, 'support': 324}, 'weighted avg': {'precision': 0.4241064624295077, 'recall': 0.6512345679012346, 'f1-score': 0.5136840890734972, 'support': 324}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6568397622290856 Training Accuracy Score:  0.6400137268359644\n",
            "Validation Loss:  0.6520474326042902 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.6512345679012346, 'recall': 1.0, 'f1-score': 0.788785046728972, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.3256172839506173, 'recall': 0.5, 'f1-score': 0.394392523364486, 'support': 324}, 'weighted avg': {'precision': 0.4241064624295077, 'recall': 0.6512345679012346, 'f1-score': 0.5136840890734972, 'support': 324}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6444133692751817 Training Accuracy Score:  0.6554564172958133\n",
            "Validation Loss:  0.643471047991798 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.6512345679012346, 'recall': 1.0, 'f1-score': 0.788785046728972, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.3256172839506173, 'recall': 0.5, 'f1-score': 0.394392523364486, 'support': 324}, 'weighted avg': {'precision': 0.4241064624295077, 'recall': 0.6512345679012346, 'f1-score': 0.5136840890734972, 'support': 324}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.637094634152501 Training Accuracy Score:  0.6533973919011667\n",
            "Validation Loss:  0.633420691603706 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.6512345679012346, 'recall': 1.0, 'f1-score': 0.788785046728972, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.3256172839506173, 'recall': 0.5, 'f1-score': 0.394392523364486, 'support': 324}, 'weighted avg': {'precision': 0.4241064624295077, 'recall': 0.6512345679012346, 'f1-score': 0.5136840890734972, 'support': 324}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6321751941097239 Training Accuracy Score:  0.6547700754975978\n",
            "Validation Loss:  0.6296887823513576 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.6512345679012346, 'recall': 1.0, 'f1-score': 0.788785046728972, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.3256172839506173, 'recall': 0.5, 'f1-score': 0.394392523364486, 'support': 324}, 'weighted avg': {'precision': 0.4241064624295077, 'recall': 0.6512345679012346, 'f1-score': 0.5136840890734972, 'support': 324}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6247223802928716 Training Accuracy Score:  0.6585449553877831\n",
            "Validation Loss:  0.6178508088702247 Validation Accuracy Score:  0.6512345679012346 \n",
            " Classification Report:  {'0': {'precision': 0.6512345679012346, 'recall': 1.0, 'f1-score': 0.788785046728972, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'accuracy': 0.6512345679012346, 'macro avg': {'precision': 0.3256172839506173, 'recall': 0.5, 'f1-score': 0.394392523364486, 'support': 324}, 'weighted avg': {'precision': 0.4241064624295077, 'recall': 0.6512345679012346, 'f1-score': 0.5136840890734972, 'support': 324}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6211140186734538 Training Accuracy Score:  0.6599176389842142\n",
            "Validation Loss:  0.6249944766362509 Validation Accuracy Score:  0.6574074074074074 \n",
            " Classification Report:  {'0': {'precision': 0.65527950310559, 'recall': 1.0, 'f1-score': 0.7917448405253283, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.017699115044247787, 'f1-score': 0.034782608695652174, 'support': 113}, 'accuracy': 0.6574074074074074, 'macro avg': {'precision': 0.827639751552795, 'recall': 0.5088495575221239, 'f1-score': 0.41326372461049027, 'support': 324}, 'weighted avg': {'precision': 0.77550609615827, 'recall': 0.6574074074074074, 'f1-score': 0.5277425806588054, 'support': 324}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6109288509100512 Training Accuracy Score:  0.6695264241592312\n",
            "Validation Loss:  0.6108884116013845 Validation Accuracy Score:  0.6851851851851852 \n",
            " Classification Report:  {'0': {'precision': 0.6741214057507987, 'recall': 1.0, 'f1-score': 0.8053435114503816, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.09734513274336283, 'f1-score': 0.1774193548387097, 'support': 113}, 'accuracy': 0.6851851851851852, 'macro avg': {'precision': 0.8370607028753994, 'recall': 0.5486725663716814, 'f1-score': 0.49138143314454563, 'support': 324}, 'weighted avg': {'precision': 0.7877765944858597, 'recall': 0.6851851851851852, 'f1-score': 0.586345271644459, 'support': 324}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6068878240598355 Training Accuracy Score:  0.6791352093342484\n",
            "Validation Loss:  0.6184697378249395 Validation Accuracy Score:  0.6851851851851852 \n",
            " Classification Report:  {'0': {'precision': 0.6741214057507987, 'recall': 1.0, 'f1-score': 0.8053435114503816, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.09734513274336283, 'f1-score': 0.1774193548387097, 'support': 113}, 'accuracy': 0.6851851851851852, 'macro avg': {'precision': 0.8370607028753994, 'recall': 0.5486725663716814, 'f1-score': 0.49138143314454563, 'support': 324}, 'weighted avg': {'precision': 0.7877765944858597, 'recall': 0.6851851851851852, 'f1-score': 0.586345271644459, 'support': 324}}\n",
            "Fold: 8\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6839176592279653 Training Accuracy Score:  0.5636363636363636\n",
            "Validation Loss:  0.6716359541529701 Validation Accuracy Score:  0.6501547987616099 \n",
            " Classification Report:  {'0': {'precision': 0.6540880503144654, 'recall': 0.985781990521327, 'f1-score': 0.7863894139886578, 'support': 211}, '1': {'precision': 0.4, 'recall': 0.017857142857142856, 'f1-score': 0.034188034188034185, 'support': 112}, 'accuracy': 0.6501547987616099, 'macro avg': {'precision': 0.5270440251572327, 'recall': 0.5018195666892349, 'f1-score': 0.410288724088346, 'support': 323}, 'weighted avg': {'precision': 0.5659832155305021, 'recall': 0.6501547987616099, 'f1-score': 0.5255641677420019, 'support': 323}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6682569055609364 Training Accuracy Score:  0.6308747855917667\n",
            "Validation Loss:  0.6568854876926967 Validation Accuracy Score:  0.6594427244582043 \n",
            " Classification Report:  {'0': {'precision': 0.6573208722741433, 'recall': 1.0, 'f1-score': 0.7932330827067668, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.017857142857142856, 'f1-score': 0.03508771929824561, 'support': 112}, 'accuracy': 0.6594427244582043, 'macro avg': {'precision': 0.8286604361370716, 'recall': 0.5089285714285714, 'f1-score': 0.41416040100250623, 'support': 323}, 'weighted avg': {'precision': 0.776144594581561, 'recall': 0.6594427244582043, 'f1-score': 0.530346764744679, 'support': 323}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6549830264081069 Training Accuracy Score:  0.6504288164665523\n",
            "Validation Loss:  0.6454175568762279 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6473331216905938 Training Accuracy Score:  0.6511149228130361\n",
            "Validation Loss:  0.6331707608132136 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.639197773946439 Training Accuracy Score:  0.6535162950257289\n",
            "Validation Loss:  0.6318373013110388 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6327708690870003 Training Accuracy Score:  0.6538593481989708\n",
            "Validation Loss:  0.6189749751772199 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6312524158446515 Training Accuracy Score:  0.6542024013722126\n",
            "Validation Loss:  0.614468399967466 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6223271204148485 Training Accuracy Score:  0.6542024013722126\n",
            "Validation Loss:  0.6167947082292466 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6183940491389707 Training Accuracy Score:  0.6555746140651801\n",
            "Validation Loss:  0.6045533886977604 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  9 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6110333748202507 Training Accuracy Score:  0.6593481989708405\n",
            "Validation Loss:  0.6034555562904903 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  10 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6102109750111898 Training Accuracy Score:  0.6679245283018868\n",
            "Validation Loss:  0.6093057479177203 Validation Accuracy Score:  0.7027863777089783 \n",
            " Classification Report:  {'0': {'precision': 0.6872964169381107, 'recall': 1.0, 'f1-score': 0.8146718146718147, 'support': 211}, '1': {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 112}, 'accuracy': 0.7027863777089783, 'macro avg': {'precision': 0.8436482084690553, 'recall': 0.5714285714285714, 'f1-score': 0.5323359073359073, 'support': 323}, 'weighted avg': {'precision': 0.7957261423341838, 'recall': 0.7027863777089783, 'f1-score': 0.6188722999868511, 'support': 323}}\n",
            "Fold: 9\n",
            "Epoch:  0 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6898927587629016 Training Accuracy Score:  0.5310463121783876\n",
            "Validation Loss:  0.6741214139120919 Validation Accuracy Score:  0.6749226006191951 \n",
            " Classification Report:  {'0': {'precision': 0.6934306569343066, 'recall': 0.9004739336492891, 'f1-score': 0.7835051546391754, 'support': 211}, '1': {'precision': 0.5714285714285714, 'recall': 0.25, 'f1-score': 0.34782608695652173, 'support': 112}, 'accuracy': 0.6749226006191951, 'macro avg': {'precision': 0.632429614181439, 'recall': 0.5752369668246445, 'f1-score': 0.5656656207978485, 'support': 323}, 'weighted avg': {'precision': 0.6511265282140517, 'recall': 0.6749226006191951, 'f1-score': 0.6324337751331159, 'support': 323}}\n",
            "Epoch:  1 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6670178135887521 Training Accuracy Score:  0.63704974271012\n",
            "Validation Loss:  0.6571377090045384 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  2 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6525007870679345 Training Accuracy Score:  0.6572898799313893\n",
            "Validation Loss:  0.6445924639701843 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  3 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6463728931432213 Training Accuracy Score:  0.6562607204116638\n",
            "Validation Loss:  0.6359815824599493 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  4 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6357268099902106 Training Accuracy Score:  0.6572898799313893\n",
            "Validation Loss:  0.6351750237601144 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  5 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6331529814363177 Training Accuracy Score:  0.6572898799313893\n",
            "Validation Loss:  0.62726362546285 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  6 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6299090209554453 Training Accuracy Score:  0.6562607204116638\n",
            "Validation Loss:  0.6288497646649679 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  7 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.6257843489203948 Training Accuracy Score:  0.657975986277873\n",
            "Validation Loss:  0.6114430342401777 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n",
            "Epoch:  8 \n",
            "\n",
            "Batch:  0 / 183\n",
            "Batch:  10 / 183\n",
            "Batch:  20 / 183\n",
            "Batch:  30 / 183\n",
            "Batch:  40 / 183\n",
            "Batch:  50 / 183\n",
            "Batch:  60 / 183\n",
            "Batch:  70 / 183\n",
            "Batch:  80 / 183\n",
            "Batch:  90 / 183\n",
            "Batch:  100 / 183\n",
            "Batch:  110 / 183\n",
            "Batch:  120 / 183\n",
            "Batch:  130 / 183\n",
            "Batch:  140 / 183\n",
            "Batch:  150 / 183\n",
            "Batch:  160 / 183\n",
            "Batch:  170 / 183\n",
            "Batch:  180 / 183\n",
            "Finished Batch: \n",
            "Training Loss:  0.622888297493992 Training Accuracy Score:  0.6610634648370497\n",
            "Validation Loss:  0.6153966018131801 Validation Accuracy Score:  0.653250773993808 \n",
            " Classification Report:  {'0': {'precision': 0.653250773993808, 'recall': 1.0, 'f1-score': 0.7902621722846442, 'support': 211}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.653250773993808, 'macro avg': {'precision': 0.326625386996904, 'recall': 0.5, 'f1-score': 0.3951310861423221, 'support': 323}, 'weighted avg': {'precision': 0.42673657372350926, 'recall': 0.653250773993808, 'f1-score': 0.516239375702972, 'support': 323}}\n"
          ]
        }
      ],
      "source": [
        "losses, class_reps, models = many_splits_training(X, y, loss, me, min_delta, random_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO8cVm0bNOFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86fcf955-5c56-4b75-b789-fa8ec16fe481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/ (stored 0%)\n",
            "  adding: content/results/xval_data_fold_3_random_state_0.txt (deflated 55%)\n",
            "  adding: content/results/class_rep_fold_3_random_state_0.pkl (deflated 13%)\n",
            "  adding: content/results/class_rep_fold_0_random_state_10.pkl (deflated 15%)\n",
            "  adding: content/results/ytrain_random_state_10.txt (deflated 90%)\n",
            "  adding: content/results/xval_data_fold_0_random_state_10.txt (deflated 54%)\n",
            "  adding: content/results/losses_fold_0_random_state_10.pkl (deflated 31%)\n",
            "  adding: content/results/yval_data_fold_3_random_state_0.txt (deflated 85%)\n",
            "  adding: content/results/model_fold_0_random_state10.pth (deflated 7%)\n",
            "  adding: content/results/ytrain_random_state_0.txt (deflated 90%)\n",
            "  adding: content/results/yval_random_state_0.txt (deflated 88%)\n",
            "  adding: content/results/xval_random_state_0.txt (deflated 59%)\n",
            "  adding: content/results/yval_random_state_10.txt (deflated 88%)\n",
            "  adding: content/results/xtrain_random_state_0.txt (deflated 59%)\n",
            "  adding: content/results/yval_data_fold_0_random_state_10.txt (deflated 86%)\n",
            "  adding: content/results/xtrain_random_state_10.txt (deflated 59%)\n",
            "  adding: content/results/xval_random_state_10.txt (deflated 58%)\n",
            "  adding: content/results/xtrain_data_fold_3_random_state_0.txt (deflated 59%)\n",
            "  adding: content/results/losses_fold_3_random_state_0.pkl (deflated 29%)\n",
            "  adding: content/results/ytrain_data_fold_3_random_state_0.txt (deflated 90%)\n",
            "  adding: content/results/model_fold_3_random_state0.pth (deflated 7%)\n",
            "  adding: content/results/ytrain_data_fold_0_random_state_10.txt (deflated 90%)\n",
            "  adding: content/results/xtrain_data_fold_0_random_state_10.txt (deflated 59%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/file_rs1020.zip /content/results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file_rs1020.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_a3SiIj8i0a0",
        "outputId": "07c651a7-503f-4568-b5ed-6c1b087e3fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e19f65ba-16c6-49d7-8e50-847a4f3c85c6\", \"file_rs1020.zip\", 8084076102)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "5X9lcIDVaDkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('losses_rs010.pickle', 'wb') as handle:\n",
        "    pickle.dump(losses, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "7ZSBN7wZkmet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('models_rs010.pickle', 'wb') as handle:\n",
        "    pickle.dump(models, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "8001kf4TaXA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_states_2 = [20]"
      ],
      "metadata": {
        "id": "fBJurwI0ixWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses, class_reps, models = many_splits_training(X, y, loss, me, min_delta, random_states_2)"
      ],
      "metadata": {
        "id": "Iv7FbxLj3zpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73bec8a13ee6454db4cb2fd30f523f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe00bcb9d0d49db9babc64763e28358",
              "IPY_MODEL_bf9d45ba21c44ef1ba2c43c8164ff757",
              "IPY_MODEL_3b5729845e314eb6844736178f00fe11"
            ],
            "layout": "IPY_MODEL_519c10b64354467b969de7b49505d9b2"
          }
        },
        "3fe00bcb9d0d49db9babc64763e28358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a568882217e43f59ff2f1121e11acae",
            "placeholder": "​",
            "style": "IPY_MODEL_269164f83c3240a0b3c8b0bb25400579",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bf9d45ba21c44ef1ba2c43c8164ff757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ccd7c071e1145a4802af093be600864",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32e4a833a36c4c69aca39ddae935dbfe",
            "value": 43
          }
        },
        "3b5729845e314eb6844736178f00fe11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2074e8869e9046158c1a886d3ce5ae5d",
            "placeholder": "​",
            "style": "IPY_MODEL_78d1bc0051104ec5adcde9acf2881b72",
            "value": " 43.0/43.0 [00:00&lt;00:00, 2.95kB/s]"
          }
        },
        "519c10b64354467b969de7b49505d9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a568882217e43f59ff2f1121e11acae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "269164f83c3240a0b3c8b0bb25400579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ccd7c071e1145a4802af093be600864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e4a833a36c4c69aca39ddae935dbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2074e8869e9046158c1a886d3ce5ae5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78d1bc0051104ec5adcde9acf2881b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4508965c7b734a2e810a7707185bc25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dc1cb57bf674eb6a7cb9902f2a6b82a",
              "IPY_MODEL_aeebb7da7bd44f15a91732ccd0131841",
              "IPY_MODEL_dd3ab474a25140e49bbc62de49cf211d"
            ],
            "layout": "IPY_MODEL_37209e7e66d8444b88497c5f2611185d"
          }
        },
        "4dc1cb57bf674eb6a7cb9902f2a6b82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a77f048fbd34f5fb5bd2f71e137fa4c",
            "placeholder": "​",
            "style": "IPY_MODEL_6f5637d5f3334db3a984a3152e192d62",
            "value": "config.json: 100%"
          }
        },
        "aeebb7da7bd44f15a91732ccd0131841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e5c85b139847faaf6811907cee6453",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe698f695cf547a9b853513d3b657b51",
            "value": 647
          }
        },
        "dd3ab474a25140e49bbc62de49cf211d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_230af5c4e7354214a7b7244fccbd27b1",
            "placeholder": "​",
            "style": "IPY_MODEL_3e1ba2c5797749f6af3ced3dc9828d55",
            "value": " 647/647 [00:00&lt;00:00, 53.7kB/s]"
          }
        },
        "37209e7e66d8444b88497c5f2611185d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a77f048fbd34f5fb5bd2f71e137fa4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5637d5f3334db3a984a3152e192d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5e5c85b139847faaf6811907cee6453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe698f695cf547a9b853513d3b657b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "230af5c4e7354214a7b7244fccbd27b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1ba2c5797749f6af3ced3dc9828d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a0fd43d371c45e28da9483ea0feb2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_593aace367da45edbaae9122da2cb5e2",
              "IPY_MODEL_6c436a5be82a4c358596b0dbd69b036a",
              "IPY_MODEL_623cd133b2fd436bb7c2717a7800c3bf"
            ],
            "layout": "IPY_MODEL_7eb0f5daee6c437abdc9440c89e96ee5"
          }
        },
        "593aace367da45edbaae9122da2cb5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71bf916bf774d5cbdf74f97a3ca98e6",
            "placeholder": "​",
            "style": "IPY_MODEL_323b6da1680547d89573cbd0487d9677",
            "value": "vocab.txt: 100%"
          }
        },
        "6c436a5be82a4c358596b0dbd69b036a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a8b390af4f046fb809a04441affeb7c",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3c2701518764e3da59b42490d99a881",
            "value": 209528
          }
        },
        "623cd133b2fd436bb7c2717a7800c3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca81a0d0fdc42c2ad8aa18175d0873a",
            "placeholder": "​",
            "style": "IPY_MODEL_e1f9a57c62f94b52b94662f4a57567d7",
            "value": " 210k/210k [00:00&lt;00:00, 3.38MB/s]"
          }
        },
        "7eb0f5daee6c437abdc9440c89e96ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71bf916bf774d5cbdf74f97a3ca98e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323b6da1680547d89573cbd0487d9677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a8b390af4f046fb809a04441affeb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c2701518764e3da59b42490d99a881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ca81a0d0fdc42c2ad8aa18175d0873a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f9a57c62f94b52b94662f4a57567d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed5dab8d790f48f1a3823a875d07786c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d477052323f4c0baa9192670eab2631",
              "IPY_MODEL_a3c07f07f50f415f81ff15d7f441041f",
              "IPY_MODEL_e08fd94f146948fc926ef8b483152a4c"
            ],
            "layout": "IPY_MODEL_0dbe4912fbee4112b65dce395bf840f0"
          }
        },
        "5d477052323f4c0baa9192670eab2631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7587d26fb0334dbbb5037702ed6d76b7",
            "placeholder": "​",
            "style": "IPY_MODEL_9350727722e3444f9117bd78384636ff",
            "value": "added_tokens.json: 100%"
          }
        },
        "a3c07f07f50f415f81ff15d7f441041f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d3513aaba64a32b8328f3cc277b6a7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed03d76d2287451ab2ae8f15f4ba14b1",
            "value": 2
          }
        },
        "e08fd94f146948fc926ef8b483152a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c860fee792c4bd5be4ff4df79748358",
            "placeholder": "​",
            "style": "IPY_MODEL_33967797d6eb4237aeefe0e6bf516ba1",
            "value": " 2.00/2.00 [00:00&lt;00:00, 109B/s]"
          }
        },
        "0dbe4912fbee4112b65dce395bf840f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7587d26fb0334dbbb5037702ed6d76b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9350727722e3444f9117bd78384636ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d3513aaba64a32b8328f3cc277b6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed03d76d2287451ab2ae8f15f4ba14b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c860fee792c4bd5be4ff4df79748358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33967797d6eb4237aeefe0e6bf516ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90b34504b85846e993391301b393994d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5664bc5dbc754951b2b4294dc74895b1",
              "IPY_MODEL_e40097ea8db0424f97abe00257b559b3",
              "IPY_MODEL_0c34ce03fe5448148669c3a150e2846e"
            ],
            "layout": "IPY_MODEL_caf3bf3230874937af99aec95fd5d29e"
          }
        },
        "5664bc5dbc754951b2b4294dc74895b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b76ec919c384594bf463a08b124ebf7",
            "placeholder": "​",
            "style": "IPY_MODEL_8f3056d613204616a7fd4dd232669601",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e40097ea8db0424f97abe00257b559b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c5d1d816064828a81e5e0db0252746",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e6007714e5342c2b8460ffe2be87ca8",
            "value": 112
          }
        },
        "0c34ce03fe5448148669c3a150e2846e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9bdd6175b9746288a5dac4762ad640b",
            "placeholder": "​",
            "style": "IPY_MODEL_0c7cc40f395b4f80b6602d2b8f79778d",
            "value": " 112/112 [00:00&lt;00:00, 7.71kB/s]"
          }
        },
        "caf3bf3230874937af99aec95fd5d29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b76ec919c384594bf463a08b124ebf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3056d613204616a7fd4dd232669601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33c5d1d816064828a81e5e0db0252746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e6007714e5342c2b8460ffe2be87ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9bdd6175b9746288a5dac4762ad640b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c7cc40f395b4f80b6602d2b8f79778d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dcff24b2ad44c66996f9340df9544be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6be6244592844ab916ff816c03c2046",
              "IPY_MODEL_5b10c98b9999495991ad11e67ef8a5ac",
              "IPY_MODEL_5935b5346ba74552aa81f88e0a713fbf"
            ],
            "layout": "IPY_MODEL_5c9784bb367e4fe48f9e9d272975598d"
          }
        },
        "c6be6244592844ab916ff816c03c2046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850b188f9fb648c08b8a690d3a1b7146",
            "placeholder": "​",
            "style": "IPY_MODEL_331f7b9da90e48e08d38fdfadc098d0b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "5b10c98b9999495991ad11e67ef8a5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d4a192722e4e9a91c6310e7f2abb51",
            "max": 438235074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15cdf1de4ea34da2802b3000ed12663b",
            "value": 438235074
          }
        },
        "5935b5346ba74552aa81f88e0a713fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c72a5fce76344789d929e90c9cf0847",
            "placeholder": "​",
            "style": "IPY_MODEL_8609ac88b7fb40f7b17c0c2257565e40",
            "value": " 438M/438M [00:03&lt;00:00, 135MB/s]"
          }
        },
        "5c9784bb367e4fe48f9e9d272975598d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850b188f9fb648c08b8a690d3a1b7146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331f7b9da90e48e08d38fdfadc098d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8d4a192722e4e9a91c6310e7f2abb51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15cdf1de4ea34da2802b3000ed12663b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c72a5fce76344789d929e90c9cf0847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8609ac88b7fb40f7b17c0c2257565e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}